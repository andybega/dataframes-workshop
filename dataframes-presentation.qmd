---
title: "Python dataframes with pandas and polars"
author: "Andreas Beger and Isaac Chung <br/> PyData Tallinn x Python CodeClub <br/> 27 November 2024"
format: 
    revealjs:
        theme: [default, styles.scss]
        embed-resources: true
execute:
  echo: true
---


## Bios

:::: {.columns}

::: {.column width="47%"}
**Andreas Beger**

- ğŸ¢ Data Scientist, Consult.
- ğŸƒâ€â™‚ï¸ğŸŒ Slow marathoner
- ğŸ“ ğŸ‡©ğŸ‡ª/ğŸ‡­ğŸ‡· â†’ ğŸ‡ºğŸ‡¸ â†’ ğŸ‡ªğŸ‡ª
- ğŸ“ PhD Political Science

:::

::: {.column width="53%"}
**Isaac Chung**

- ğŸ¢ Staff Data Scientist, Wrike
- ğŸŠâ€â™‚ï¸ğŸš´ğŸƒâ€â™‚ï¸ Fast triathlete
- ğŸ“ ğŸ‡­ğŸ‡° â†’ ğŸ‡¨ğŸ‡¦ â†’ ğŸ‡ªğŸ‡ª
- ğŸ“ MS Machine Learning

:::

****

ğŸ We are also the PyData Tallinn co-organizers.

::::

## Agenda

::: {.incremental}

0. Prelude: setting up, what are dataframes?
1. (notebook) pandas and basic dataframe concepts and operations
2. (notebook) polars, retread basic and also cover more advanced operations
3. The bigger picture: pandas vs polars, other frameworks

:::

## Setting up - link to repo

[https://github.com/andybega/dataframes-workshop](https://github.com/andybega/dataframes-workshop)

![](media/dataframes-repo-qr-code.png){fig-align="center"}

## Using GitHub Codespaces

![](media/setup-codespaces-1.png){fig-align="center"}

## Open dataframes.ipynb

![](media/setup-codespaces-2.png){fig-align="center"}

## To just follow along

![](media/setup-just-follow.png){fig-align="center"}

## While we wait

::: {.incremental}

- Who has used pandas before?
- polars?
- Another data framework in Python, e.g. database + SQL?
- Does code like this mean anything to you?
  ```r
  titanic %>% 
    select(Pclass, Survived) %>% 
    group_by(Pclass) %>% 
    summarize(passengers = n(), surv_rate = mean(Survived))
  ```

:::

# What are dataframes?

## Definition 

:::: {.columns  .v-center-container}

::: {.column width="60%" .incremental}

- Dataframes are a data type representing 2D tables 
- Where the columns have names
- Unlike matrices or arrays, columns might have different data types
- And the rows are identified by one or more ID variables

:::

::: {.column width="10%"}

:::

::: {.column width="30%" .fragment}

```{python}
#| echo: false
#| output: asis
import polars as pl
df = pl.from_dicts([
    {"x": 1, "y": 2, "group": "a"},
    {"x": 4, "y": 7, "group": "b"},
    {"x": 3, "y": 8, "group": "a"},
    {"x": 9, "y": 2, "group": "b"}
])
with pl.Config(
    tbl_formatting="MARKDOWN",
    tbl_hide_column_data_types=True,
    tbl_hide_dataframe_shape=True,
):
    print(df)
```

:::

::::

## Why?

. . . 

Imagine working with tabular data if we didn't have dataframes and associated methods. 

::: {.fragment}

```{python}
by_rows = [
    {"x": 1, "y": 2, "group": "a"},
    {"x": 4, "y": 7, "group": "b"},
    {"x": 3, "y": 8, "group": "a"},
    {"x": 9, "y": 2, "group": "b"}
]
```

:::

<br/>

::: {.fragment}

```{python}
by_columns = {
    "x": [1, 4, 3, 9],
    "y": [2, 7, 8, 2],
    "group": ["a", "b", "a", "b"]
}
```

:::

# Section 1: pandas

![](media/pandas-logo.png)

## History

:::: {.columns}

::: {.column width="50%"}

- Created by Wes McKinney, now at Posit PBC
- Started in 2008
- Originally built on top of `numpy`

:::

::: {.column width="50%"}

![](media/wes-mckinney.png)

:::

::::

## Getting started {.smaller}

. . . 

```{python}
#| echo: true
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "quarter": [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],
    "x": np.random.randn(12),
    "date": pd.date_range("2024-01-01", periods=12, freq="MS")
})

df.head()
```

## Components of a dataframe {.smaller}

. . . 

Series

```{python}
df.x
```

. . . 

Columns

```{python}
df.columns
```

. . . 

Index

```{python}
df.index
```

# Let's look at some real data

Estonian vehicle accident data

- ğŸ“– âœï¸ read and write
- ğŸ”¬ inspect


## Input - reading data {.smaller}

. . . 

```{python}
accidents = pd.read_csv("data/estonia-traffic-accidents-clean.csv")
```

## Inspecting {.smaller}

. . . 

```{python}
accidents.shape
```

. . . 

```{python}
accidents.columns
```

. . . 

```{python}
#| eval: false
accidents.head()
```

```{python}
#| echo: false
accidents[["date", "persons_involved", "killed", "injured", "county"]].head()
```

## Inspecting {.smaller}

```{python}
accidents.info()
```

# What time period does the data cover?

- ğŸ›’ select columns
- ğŸ¥ª mutate, add columns

## Selecting columns {.smaller}

Different ways, one is indexing with `[]`:

. . . 

```{python}
accidents["date"].head(4)
```

. . . 

Multiple columns

. . . 

```{python}
#| output: true
accidents[["date", "county"]].head(4)
```

## Mutating columns {.smaller}

Right now date is stored as a string:

```{python}
accidents["date"][0]
```

```{python}
type(accidents["date"][0])
```

. . . 

<br/>

Convert it to proper data type:

```{python}
accidents["date"] = pd.to_datetime(accidents["date"])
type(accidents["date"][0])
```

## Pandas Series {.smaller}

```{python}
dates = accidents["date"]
type(dates)
```

<br/>

. . .  

```{python}
start = accidents["date"].min()
end = accidents["date"].max()
print(f"First accident: {start}\nLast accident: {end}")
```

<br/>

. . . 

```{python}
accidents["accident_type"].value_counts()
```

. . . 

# How many accidents were in Harju county?

- ğŸ” filter rows

## Filtering rows {.smaller}

```{python}
accidents[accidents["county"] == "Harju maakond"].shape
```

<br/>

. . . 

```{python}
accidents["county"] == "Harju maakond"
```

# How many people were harmed in total?

- ğŸ¥ª mutate, add columns

## Mutating dataframes {.smaller}

. . . 

```{python}
accidents["killed_or_injured"] = accidents["killed"] + accidents["injured"]
accidents[['killed', 'injured', 'killed_or_injured']].head()
```

. . . 

<br/>

```{python}
accidents["killed_or_injured"].sum()
```

. . . 

```{python}
sum(accidents["killed_or_injured"])
```

# What about by accident type?

- ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ group and aggregate

## Grouping and summarizing {.smaller}

. . . 

```{python}
by_type = accidents.groupby("accident_type").agg({"killed_or_injured": "sum"})
```

. . . 

```{python}
by_type
```

## (Optional) More on indices

See notebook.

## (Optional) Cleaning the accidents data

See notebook. 

## pandas is great

. . .

<br/>
2017, Wes McKinney (creator of pandas):

. . . 

> **10 Things I Hate About Pandas **

. . . 

- Inefficient memory management, need 5-10x data size
- Eager evaluation â†’ limited query planning
- No multi-core

::: {.fragment}

- Apache Arrow (2016 - ...)

:::


::: aside
[https://wesmckinney.com/blog/apache-arrow-pandas-internals/](https://wesmckinney.com/blog/apache-arrow-pandas-internals/)
:::


# Section 2: polars

![](media/polars-logo.jpg)



## History

:::: {.columns}

::: {.column width="60%"}

- Created in 2020 by Ritchie Vink
- Structural engineer gone data scientist/engineer
- Written in Rust
- Uses Arrow as internal representation 

:::

::: {.column width=40%}

![](media/ritchie-vink.jpg)

:::

:::: 


## Getting started {.smaller}

```{python}
#| eval: false
import polars as pl

accidents = pl.read_csv("data/estonia-traffic-accidents-clean.csv")
accidents.head()
```

. . . 

```{python}
#| echo: false
import polars as pl

accidents = pl.read_csv("data/estonia-traffic-accidents-clean.csv")
accidents.select(accidents.columns[0:5]).head()
```

## polars is different from pandas

But, we can always convert back and forth:

```python
import pyarrow

df = pl.DataFrame({"x": [1, 2, 3], "y": [4, 5, 6]})
# to make this a pandas dataframe
# (requires pyarrow)
df_pd = df.to_pandas()
# to convert it back to polars dataframe
df_pl = pl.DataFrame(df_pd)
```

# How many were harmed in the biggest accident?

- ğŸ›’ select columns
- ğŸ¥ª mutate, add columns
- ğŸ” filter rows

**Expressions**!

## Selecting columns {.smaller}

```{python}
accidents.select("date", "county").head()
```

## Expressions {.smaller}

Expressions are abstract, composable **data transformations** that are executed with a **context** that provides data. 

. . . 

```{python}
accidents.select(pl.col("date")).head(1)
```

. . . 

```{python}
foo = pl.col("date")
foo
```

. . . 

```{python}
accidents.select(foo).head(1)
```

## They can be composed {.smaller}

. . . 

How many people were harmed in the biggest accident in our data?

. . . 

```{python}
accidents.select(
    # select 'killed'
    pl.col("killed")
    # add 'injured'
    .add(pl.col("injured"))
    # give the result a new column name
    .alias("killed_or_injured")
    # identify the max value
    .max())
```


## Expressions work in multiple contexts

- `select()`
- `filter()`
- `with_columns()`: mutating dataframes
- `group_by()` and aggregations

# How many accidents were in Harju county?

- ğŸ” filter rows

## Filtering rows 

```{python}
accidents.filter(pl.col("county").eq("Harju maakond")).shape
```

. . . 

```{python}
accidents.filter(pl.col("county")=="Harju maakond").shape
```

. . . 

<br/>

Let's be slightly lazy:

```{python}
accidents.filter(pl.col("county").str.contains("Harju")).shape
```

# What fraction of people involved in an accident were harmed?

- ğŸ¥ª mutate, add columns

## Mutating dataframes {.smaller}

`with_columns()` + expressions

. . . 

```{python}
accidents = accidents.with_columns(
    pl.col("killed").add(pl.col("injured")).alias("killed_or_injured"),
    pl.col("killed").add(pl.col("injured")).truediv(pl.col("persons_involved")).alias("harmed_rate")
)
accidents.select(["date", "persons_involved", "killed_or_injured", "harmed_rate"]).head(5)
```

# Which county had the most accidents?

- ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ group and aggregate

## Group and summarize/aggregate {.smaller}

`group_by()` + `agg()` or `with_columns()`

. . . 

```{python}
by_county = (accidents
             .group_by("county")
             .agg(pl.len().alias("accidents"),
                  pl.col("killed_or_injured").sum())
             .sort("accidents", descending=True)
)
by_county.head()
```

# What's the per capita accident victim rate, by county?

(Optional)

## Joining dataframes {.smaller}

. . . 

```{python}
county_pop = (pl.read_csv("data/county-pop.csv", skip_rows=2)
              .rename({"County": "county", "Age groups total": "population"})
              .select(["county", "population"])
              # this has "county" in the county names, not "maakond"
              .with_columns(pl.col("county").str.replace("county", "maakond"))
              )

by_county_w_pop = by_county.join(county_pop, on="county", how="left")
by_county_w_pop.head(3)
```

## Joining dataframes {.smaller}

Now we can use some simple select + expressions do to the math:

. . . 

```{python}
by_county_w_pop.select(
    pl.col("county"), 
    pl.col("killed_or_injured"),
    pl.col("killed_or_injured").truediv(pl.col("population")).mul(1000).alias("rate/1000")
    ).head(3)
```

# Who wears reflectors? Men or women? Young or old?

We will use new data for this. 

- ğŸ§± reshape wide, long

## Reshaping / pivoting dataframes {.smaller}

. . . 

```{python}
reflectors = (pl.read_csv("data/reflectors.csv", has_header=True, separator=";", skip_rows=2)
              .filter(pl.col("Sex").ne("Men and women"))
              .drop(["Type of data", "Year", "All age groups (16-64)"])
              .sort("Reflector use", "Sex")
)
reflectors.head()
```


## Reshaping / pivoting dataframes {.smaller}

```{python}
reflectors = (reflectors
              .unpivot(index=["Reflector use", "Sex"], 
                       variable_name="age_group", 
                       value_name="percentage")
            .sort("Reflector use", "Sex", "age_group")
)
reflectors.head()
```

## Plot reflector use by age and gender {.smaller}

. . . 

```{python}
reflectors.get_column("Reflector use").unique().to_list()
```

. . . 

```{python}
(reflectors
 .filter(pl.col("Reflector use").eq("Never"))
 .plot.line(x = "age_group", y = "percentage", color = "Sex")
 .properties(width=700, height=300)
)
```

## Modified plot {.smaller}

One category is "Never walk on dark streets, roads"...ğŸ§

. . . 

```{python}
(reflectors
 .with_columns(pl.col("Reflector use").str.replace("Never walk on dark streets, roads", "Never"))
 .group_by(["Reflector use", "Sex", "age_group"])
 .agg(pl.col("percentage").sum())
 .filter(pl.col("Reflector use").eq("Never"))
 .sort(["age_group", "Sex"])
 .plot.line(x = "age_group", y = "percentage", color = "Sex")
 .properties(width=700, height=300)
)
```

## Why you should plot your data ğŸ˜¼ {.smaller}

:::: {.columns}

::: {.column width="50%" .fragment}

```{python}
df1 = pl.read_csv("data/dataset1.csv")
df1.shape
```

::: {.fragment}

```{python}
stats = ["mean", "std", "25%", "75%"]
(df1
 .describe()
 .filter(pl.col("statistic").is_in(stats))
)
```

:::

:::

::: {.column width="50%" .fragment}

```{python}
df2 = pl.read_csv("data/dataset2.csv")
df2.shape
```

::: {.fragment}

```{python}
stats = ["mean", "std", "25%", "75%"]
(df2
 .describe()
 .filter(pl.col("statistic").is_in(stats))
)
```

:::

:::

::::

## Why you should plot pt2

:::: {.columns}

::: {.column width="50%" .fragment}

```{python}
df1.plot.point("x", "y")
```

:::

::: {.column width="50%" .fragment}

```{python}
df2.plot.point("x", "y")
```

:::

::::

::: {.fragment}

ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–

:::


# The big picture

## Andy is a polars stan {.smaller}

::: {.fragment}

![](media/star-history.png){width=70% fig-align="center"}

:::

::: aside
https://star-history.com/#apache/spark&pola-rs/polars&pandas-dev/pandas&narwhals-dev/narwhals&duckdb/duckdb&Date 
:::



## Comparison

:::: {.columns}

::: {.column width="50%"}

**pandas**

- âœ… Very widely used and supported
- âœ… Stable
- â“ More imperative, traditional API
- âŒ Inconsistent API, multiple ways of doing the same thing

:::

::: {.column width="50%"}

**polars**

- âœ… More consistent, functional-style API
- âœ… Faster, less memory footprint
- âœ… Works with OOM datasets out of the box
- âŒ Not as widely adopted yet

:::

::::


## Other frameworks

::: {.incremental}

- [Narwhals](https://narwhals-dev.github.io/narwhals/)
- [DuckDB](https://duckdb.org)

:::

## Thank you!

Scan this and let us know how we did ğŸ¤—

![](media/pydata-meetup-feedback-logo.png){fig-align="center"}