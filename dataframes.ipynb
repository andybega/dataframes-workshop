{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"quarter\": [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
    "    \"x\": np.random.randn(12),\n",
    "    \"date\": pd.date_range(\"2024-01-01\", periods=12, freq=\"MS\")\n",
    "})\n",
    "\n",
    "df = pd.DataFrame({\n",
    "\n",
    "})\n",
    "\n",
    "# cover pandas indexes\n",
    "\n",
    "# make a cleaned up version of accidents and use that first to illustrate\n",
    "# basic stuff\n",
    "# then go over the cleaning steps and do them\n",
    "\n",
    "\n",
    "accidents = pd.read_csv(\"data/estonia-traffic-accidents.csv\")\n",
    "\n",
    "accidents.head()\n",
    "\n",
    "accidents.info()\n",
    "\n",
    "accidents[\"Toimumisaeg\"]\n",
    "\n",
    "keep = [\"Toimumisaeg\", \"Isikuid\", \"Hukkunuid\", \"Vigastatuid\", \"Maakond (PPA)\",\n",
    "        \"Jalak채ija osalusel\", \"Liiklus천nnetuse liik [1]\", \"Valgustus [1]\"]\n",
    "\n",
    "accidents = accidents[keep]\n",
    "\n",
    "translate_columns = {\"Toimumisaeg\": \"date\", \"Isikuid\": \"persons_involved\", \n",
    "                     \"Hukkunuid\": \"killed\", \"Vigastatuid\": \"injured\", \n",
    "                     \"Maakond (PPA)\": \"county\", \n",
    "                     \"Jalak채ija osalusel\": \"pedestrian_involved\", \n",
    "                     \"Liiklus천nnetuse liik [1]\": \"accident_type\", \n",
    "                     \"Valgustus [1]\": \"light_conditions\"}\n",
    "\n",
    "accidents = accidents.rename(columns=translate_columns)\n",
    "\n",
    "# fix date\n",
    "\n",
    "# create a new column: killed + injured\n",
    "\n",
    "# talk about missing values and filter those out\n",
    "\n",
    "# talk about data types and fix those\n",
    "\n",
    "# how many people killed over time?\n",
    "\n",
    "# summarize total accidents by county\n",
    "\n",
    "# merge in country population, summarize by county rate\n",
    "\n",
    "# for pivoting, use one of the health datasets\n",
    "reflectors = pd.read_csv(\"data/reflectors.csv\", skiprows=2, header=1, sep=\";\")\n",
    "\n",
    "\n",
    "# split this file but just use it to make a point about also plotting data\n",
    "datasaurus = pd.read_csv(\"data/datasaurus.csv\")\n",
    "\n",
    "df1 = datasaurus[datasaurus[\"dataset\"] == \"away\"].drop(\"dataset\", axis=1)\n",
    "df2 = datasaurus[datasaurus[\"dataset\"] == \"dino\"].drop(\"dataset\", axis=1)\n",
    "\n",
    "# write df1, df2 out to separate csv files\n",
    "\n",
    "df1.shape\n",
    "df2.shape\n",
    "\n",
    "df1.describe()\n",
    "df2.describe()\n",
    "\n",
    "# just gonna do this in polars, ugh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import altair as alt\n",
    "\n",
    "# redo the basic examples from above\n",
    "\n",
    "# datasuraus stuff from above\n",
    "pl.DataFrame(df1).plot.point(\"x\", \"y\")\n",
    "pl.DataFrame(df2).plot.point(\"x\", \"y\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataframes_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
