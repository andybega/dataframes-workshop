[
  {
    "objectID": "dataframes.html",
    "href": "dataframes.html",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "",
    "text": "Andreas Beger and Isaac Chung\nPython Code Club x PyData Tallinn\n27 November 2024\nThe source code for this notebook is github.com/andybega/dataframes-workshop."
  },
  {
    "objectID": "dataframes.html#section-1-pandas",
    "href": "dataframes.html#section-1-pandas",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "Section 1: pandas",
    "text": "Section 1: pandas\nWe will start with pandas, the original and most widely used dataframe and data analysis library in Python.\n\n\n\n\nGetting Started\nWe first need to import pandas. Weâ€™ll also import another package, numpy, which implements data types for vectors and matrices. Pandas is built on top of numpy, but we only import it here to make it easier to generate an example data frame.\n\nimport numpy as np\nimport pandas as pd\n\n# Create an example data frame\ndf = pd.DataFrame({\n    \"quarter\": [1, 1, 2, 2, 3],\n    \"x\": np.random.randn(5),\n    \"date\": pd.date_range(\"2024-01-01\", periods=5, freq=\"MS\")\n})\n\ndf\n\n\n\n\n\n\n\n\nquarter\nx\ndate\n\n\n\n\n0\n1\n-0.522780\n2024-01-01\n\n\n1\n1\n1.826809\n2024-02-01\n\n\n2\n2\n-0.487441\n2024-03-01\n\n\n3\n2\n-0.526952\n2024-04-01\n\n\n4\n3\n-1.570983\n2024-05-01\n\n\n\n\n\n\n\n\n\nComponents of a dataframe\nPandas DataFrames consist of three components:\n\nOne or more Series, which are the columns in the DataFrame.\nThe names for the series, i.e.Â column names of the dataframe.\nThe row names for each row in the dataframe, which pandas calls the Index.\n\n\nSeries\n\ndf.x\n\n0   -0.522780\n1    1.826809\n2   -0.487441\n3   -0.526952\n4   -1.570983\nName: x, dtype: float64\n\n\n(Note how each series can have a different data type, unlike in a matrix or an array.)\n\n\nColumns\n\ndf.columns\n\nIndex(['quarter', 'x', 'date'], dtype='object')\n\n\n\n\nIndex\n\ndf.index\n\nRangeIndex(start=0, stop=5, step=1)\n\n\nSince we didnâ€™t explicitly set an index when we created the dataframe, itâ€™s just a sequence of numbers starting at 0. Indexes are actually a key concept in pandas and weâ€™ll talk a little bit more about them later.\n\n\n\nInput: reading data from elsewhere\nPandas can import dataframes from a variety of external sources like text files, JSON, Excel spreadsheets, APIs, and SQL databases. See the input/output documentation for more information.\nWeâ€™re going to read data on Estonian vehicle accidents from a comma-separated variable (CSV) file, one of the most common text file types for storing data.\n(The accidents data are from the Estonian open data portal.)\n\naccidents = pd.read_csv(\"data/estonia-traffic-accidents-clean.csv\")\n\n\n\nInspecting\nOne of the first things we might want to do with a new dataset is to get our bearings on some basic characteristics of the data.\n\nHow many rows and columns are there?\n\naccidents.shape\n\n(14259, 8)\n\n\n\n\nWhat are the column names?\n\naccidents.columns\n\nIndex(['date', 'persons_involved', 'killed', 'injured', 'county',\n       'pedestrian_involved', 'accident_type', 'light_conditions'],\n      dtype='object')\n\n\n\n\nWhat does the data look like?\n\naccidents.head()\n\n\n\n\n\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\npedestrian_involved\naccident_type\nlight_conditions\n\n\n\n\n0\n2014-10-24 08:45:00\n2\n0\n1\nHarju maakond\n1\nJalakÃ¤ijaÃµnnetus\nValge aeg\n\n\n1\n2014-10-24 13:45:00\n2\n0\n1\nHarju maakond\n0\nKokkupÃµrge\nValge aeg\n\n\n2\n2014-08-11 00:00:00\n2\n0\n1\nHarju maakond\n0\nKokkupÃµrge\nValge aeg\n\n\n3\n2014-11-17 17:32:00\n2\n0\n2\nHarju maakond\n0\nKokkupÃµrge\nPimeda aeg\n\n\n4\n2015-04-28 07:55:00\n2\n0\n1\nHarju maakond\n0\nKokkupÃµrge\nValge aeg\n\n\n\n\n\n\n\n\n\nDo we have missing data? What are the data types?\n\naccidents.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14259 entries, 0 to 14258\nData columns (total 8 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   date                 14259 non-null  object\n 1   persons_involved     14259 non-null  int64 \n 2   killed               14259 non-null  int64 \n 3   injured              14259 non-null  int64 \n 4   county               14259 non-null  object\n 5   pedestrian_involved  14259 non-null  int64 \n 6   accident_type        14259 non-null  object\n 7   light_conditions     14259 non-null  object\ndtypes: int64(4), object(4)\nmemory usage: 891.3+ KB\n\n\nWe could also have used accidents.dtypes to get the data types.\nNote that, if you look back at the number of rows we looked up before, youâ€™ll notice that none of the columns have missing values, and that all but one of the data types look correct. This is because this is an already cleaned up version of the data. Below in this notebook you can also see what we did to clean up the data.\n\n\n\nSelecting columns\nThere are various ways to do this, including the &lt;dataframe&gt;.&lt;column&gt; notation we used above. One alternative is the square bracket &lt;dataframe&gt;.[]:\n\naccidents[\"date\"].head()\n\n0    2014-10-24 08:45:00\n1    2014-10-24 13:45:00\n2    2014-08-11 00:00:00\n3    2014-11-17 17:32:00\n4    2015-04-28 07:55:00\nName: date, dtype: object\n\n\nTo select multiple columns we can use a list with the column names as the argument:\n\naccidents[[\"date\", \"county\"]].head()\n\n\n\n\n\n\n\n\ndate\ncounty\n\n\n\n\n0\n2014-10-24 08:45:00\nHarju maakond\n\n\n1\n2014-10-24 13:45:00\nHarju maakond\n\n\n2\n2014-08-11 00:00:00\nHarju maakond\n\n\n3\n2014-11-17 17:32:00\nHarju maakond\n\n\n4\n2015-04-28 07:55:00\nHarju maakond\n\n\n\n\n\n\n\n\n\nMutating columns\nThe dateas are currently stored as strings (object). We should fix that.\n(pandas uses the object data types by default for strings, even though this can store arbitrary Python objects. This is for historical reasons related to originally being built on top of numpy. More on pandas text data types.)\n\naccidents[\"date\"][0]\n\n'2014-10-24 08:45:00'\n\n\n\ntype(accidents[\"date\"][0])\n\nstr\n\n\n\naccidents[\"date\"] = pd.to_datetime(accidents[\"date\"])\naccidents[\"date\"][0]\n\nTimestamp('2014-10-24 08:45:00')\n\n\n\n\nSidebar: Pandas Series\nLetâ€™s spend a hot second looking at an individual series.\n\ndates = accidents[\"date\"]\ntype(dates)\n\npandas.core.series.Series\n\n\n\nWhat date range does the data cover?\nSeries have their own methodsâ€¦\n\nstart = accidents[\"date\"].min()\nend = accidents[\"date\"].max()\nprint(f\"First accident: {start}\\nLast accident: {end}\")\n\nFirst accident: 2011-01-05 00:00:00\nLast accident: 2021-12-31 23:45:00\n\n\n\n\nWhat types of accidents were there?\nThe Series.value_counts() method is a quite useful method for tabulating categorical variables:\n\naccidents[\"accident_type\"].value_counts()\n\naccident_type\nKokkupÃµrge            5605\nÃœhesÃµidukiÃµnnetus     3946\nJalakÃ¤ijaÃµnnetus      3386\nMuu liiklusÃµnnetus    1262\nTeadmata                60\nName: count, dtype: int64\n\n\n\n\nFilter rows\nOftentimes we donâ€™t need all rows in a dataframe to answer a specific question. This is commonly called filtering or subsetting rows.\n\n\nHow many of the accidents were in Harju county?\nWe have a â€œcountyâ€ column, so we can use that to look at only Harju county. As with selecting columns, there are multiple ways to do this in pandas. One of the basic ones is to again use the &lt;dataframe&gt;.[] square brackets.\n\n\naccidents[accidents[\"county\"] == \"Harju maakond\"].shape\n\n(7000, 8)\n\n\nAnother sidebar â€“ Why does this work? The part inside the outer square brackets creates a boolean vector:\n\naccidents[\"county\"] == \"Harju maakond\"\n\n0         True\n1         True\n2         True\n3         True\n4         True\n         ...  \n14254    False\n14255    False\n14256     True\n14257    False\n14258    False\nName: county, Length: 14259, dtype: bool\n\n\nWhen we pass this boolean vector to the square brackets, it uses it to filter rows. Rather than select columns, like it did with `accidents[â€œcountyâ€].\nYeah, itâ€™s weird and inconsistent, which is one of the things people complain about with pandas.\nWhatâ€™s more, there are many more ways to select and filter. See the â€œIndexing and selecting dataâ€ documentation for all the various methods pandas has, both for column selecting and row filtering.\n\n\n\nMutate: add a new column\nWeâ€™ve covered how to alter an existing column. We can actually use the same method to add a new column.\n\nHow many people were killed or injured, overall?\n\naccidents[\"killed_or_injured\"] = accidents[\"killed\"] + accidents[\"injured\"]\n\naccidents[['killed', 'injured', 'killed_or_injured']].head()\n\n\n\n\n\n\n\n\nkilled\ninjured\nkilled_or_injured\n\n\n\n\n0\n0\n1\n1\n\n\n1\n0\n1\n1\n\n\n2\n0\n1\n1\n\n\n3\n0\n2\n2\n\n\n4\n0\n1\n1\n\n\n\n\n\n\n\n\naccidents[\"killed_or_injured\"].sum()\n\nnp.int64(18021)\n\n\n\n\n\nGroup and summarize\nOftentimes we want to summarize our data over some group that is defined by one of the variables. To do this we usually want to use a combination of groupby and agg.\n\nHow many people were harmed, by accident type?\n\n# summarize total accidents by something\nby_type = accidents.groupby(\"accident_type\").agg({\"killed_or_injured\": \"sum\"})\nby_type\n\n\n\n\n\n\n\n\nkilled_or_injured\n\n\naccident_type\n\n\n\n\n\nJalakÃ¤ijaÃµnnetus\n3548\n\n\nKokkupÃµrge\n7951\n\n\nMuu liiklusÃµnnetus\n1436\n\n\nTeadmata\n70\n\n\nÃœhesÃµidukiÃµnnetus\n5016\n\n\n\n\n\n\n\n\n\n\n(Optional) More on Indexes\nIn the table above, you might noticed that the â€œaccident_typeâ€ is now for some reason shown differently from the â€œkilled_or_injuredâ€ variable. Indeed, if we check the columns, itâ€™s not there anymore:\n\nby_type.columns\n\nIndex(['killed_or_injured'], dtype='object')\n\n\nWhat happened is that when we did the group by and agg, pandas moved â€œaccident_typeâ€ to the Index.\n\nby_type.index\n\nIndex(['JalakÃ¤ijaÃµnnetus', 'KokkupÃµrge', 'Muu liiklusÃµnnetus', 'Teadmata',\n       'ÃœhesÃµidukiÃµnnetus'],\n      dtype='object', name='accident_type')\n\n\nSince we hadnâ€™t set an index when we imported the data from CSV, this previously was just an integer count from 0, which you can see above when we showed the first few rows of the data with head(). Now itâ€™s â€œaccident_typeâ€.\npandas extensively uses indexes for various operations. There are event hierarchical MultiIndexes that consist of more than one variable.\nThere are really only two important things to know about pandas Indexes.\nFirst, there are two kinds of pandas users:\n\nThose that love indexes and use them extensively. Such index powerusers are rumored to exist, at least they say.\nPeople like me who donâ€™t use them unless forced to.\n\nSecond, indexes are like variables, but moved to the row labels. You can move them back and forth with two functions:\n\nset_index(&lt;keys&gt;): move columns to the index;  can be a column name or list of names.\nreset_index(): move the variables in the current index back to the dataframe as columns.\n\n\nHow many people were harmed, by year?\nTo further explore this, letâ€™s look at the number of people harmed, by year.\n\nby_year = (accidents\n           .loc[:, [\"date\", \"killed_or_injured\", \"persons_involved\"]]\n           .resample(rule=\"YE\", on=\"date\")\n           .sum()\n)\n\nby_year.head()\n\n\n\n\n\n\n\n\nkilled_or_injured\npersons_involved\n\n\ndate\n\n\n\n\n\n\n2011-12-31\n533\n722\n\n\n2012-12-31\n1713\n2289\n\n\n2013-12-31\n1714\n2271\n\n\n2014-12-31\n1758\n2429\n\n\n2015-12-31\n1773\n2859\n\n\n\n\n\n\n\nThis uses a bit more complicated code we wonâ€™t explain in more detail. .loc[] is on the of the alternative select/filter methods. resample() is like groupby() but for time series. Because the code is quite long for one line, we do something called method chaining, where we put each new method call on a new line. This requires wrapping the whole statement in parentheses.\nThe date column has been moved to the index. Since weâ€™ve aggregated the data to yearly, it would be nice, e.g.Â for plotting, if we just had the years in a column, not the misleading full date times.\n\n# Move date back to a column; note how we get a new dummy 0,1,... index\nby_year = by_year.reset_index()\nby_year.head()\n\n\n\n\n\n\n\n\ndate\nkilled_or_injured\npersons_involved\n\n\n\n\n0\n2011-12-31\n533\n722\n\n\n1\n2012-12-31\n1713\n2289\n\n\n2\n2013-12-31\n1714\n2271\n\n\n3\n2014-12-31\n1758\n2429\n\n\n4\n2015-12-31\n1773\n2859\n\n\n\n\n\n\n\n\n# To extract the year from the date we can use this:\nby_year[\"date\"].dt.year.head()\n\n0    2011\n1    2012\n2    2013\n3    2014\n4    2015\nName: date, dtype: int32\n\n\n\n# Create a new column with the year\nby_year[\"year\"] = by_year[\"date\"].dt.year\n# Drop the date column; we could also do this by selecting all columns but\n# the one we want to drop, but this is more explicit\nby_year = by_year.drop(\"date\", axis=1)\n# bring year to the first position\nby_year = by_year[[\"year\", \"persons_involved\", \"killed_or_injured\"]]\nby_year\n\n\n\n\n\n\n\n\nyear\npersons_involved\nkilled_or_injured\n\n\n\n\n0\n2011\n722\n533\n\n\n1\n2012\n2289\n1713\n\n\n2\n2013\n2271\n1714\n\n\n3\n2014\n2429\n1758\n\n\n4\n2015\n2859\n1773\n\n\n5\n2016\n3171\n1874\n\n\n6\n2017\n2906\n1725\n\n\n7\n2018\n3131\n1886\n\n\n8\n2019\n2923\n1752\n\n\n9\n2020\n2577\n1592\n\n\n10\n2021\n2735\n1701\n\n\n\n\n\n\n\n\n\n\n(Optional) Cleaning the accidents data\nWe mentioned above that the accidents data is already pretty clean. Thatâ€™s because we did the below to clean it up. If youâ€™re curious about this (great!), you can add more code cells and copy/paste each segment so you can see some intermediary output as well.\n\nimport dateparser  # for fixing the raw dates\n\naccidents = pd.read_csv(\"data/estonia-traffic-accidents.csv\")\n\naccidents.head()\n\naccidents.info()\n\n# Let's only keep a couple of columns for the workshop\nkeep = [\"Toimumisaeg\", \"Isikuid\", \"Hukkunuid\", \"Vigastatuid\", \"Maakond (PPA)\",\n        \"JalakÃ¤ija osalusel\", \"LiiklusÃµnnetuse liik [1]\", \"Valgustus [1]\"]\naccidents = accidents[keep]\n\n# Translate the column names to English\ntranslate_columns = {\"Toimumisaeg\": \"date\", \"Isikuid\": \"persons_involved\", \n                     \"Hukkunuid\": \"killed\", \"Vigastatuid\": \"injured\", \n                     \"Maakond (PPA)\": \"county\", \n                     \"JalakÃ¤ija osalusel\": \"pedestrian_involved\", \n                     \"LiiklusÃµnnetuse liik [1]\": \"accident_type\", \n                     \"Valgustus [1]\": \"light_conditions\"}\naccidents = accidents.rename(columns=translate_columns)\n\n# The original dates have a mix of formats. We're going to use the dateparser\n# library to help parse these. \naccidents[\"date\"] = accidents[\"date\"].apply(lambda x: dateparser.parse(x, languages=[\"en\"]))\n\n# We've got missing data in several columns. Let's drop those rows.\n# Usually you'd want to investigate what is missing and why, but it's fine\n# for the workshop since we are just illustrating, not trying to learn anything\n# about traffic accidents. \naccidents.isna().sum()\naccidents = accidents.dropna()\n\n# Some of the columns are float but should be integer values.\naccidents = accidents.astype({\"persons_involved\": \"int64\",\n                              \"pedestrian_involved\": \"int64\"})\n\n# write out the cleaned data. \n# accidents.to_csv(\"data/estonia-traffic-accidents-clean.csv\", index=False)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 15708 entries, 0 to 15707\nData columns (total 53 columns):\n #   Column                                         Non-Null Count  Dtype  \n---  ------                                         --------------  -----  \n 0   Juhtumi nr                                     15708 non-null  object \n 1   Toimumisaeg                                    15708 non-null  object \n 2   Isikuid                                        15633 non-null  float64\n 3   Hukkunuid                                      15708 non-null  int64  \n 4   Vigastatuid                                    15708 non-null  int64  \n 5   SÃµidukeid                                      15633 non-null  float64\n 6   Aadress (PPA)                                  14601 non-null  object \n 7   Maja nr (PPA)                                  6686 non-null   object \n 8   TÃ¤nav (PPA)                                    14012 non-null  object \n 9   Ristuv tÃ¤nav (PPA)                             2757 non-null   object \n 10  Maakond (PPA)                                  14676 non-null  object \n 11  Omavalitsus (PPA)                              14670 non-null  object \n 12  Asustus (PPA)                                  8822 non-null   object \n 13  Asula                                          15708 non-null  object \n 14  LiiklusÃµnnetuse liik [1]                       15708 non-null  object \n 15  LiiklusÃµnnetuse liik [3]                       15708 non-null  object \n 16  Kergliikurijuhi osalusel                       15563 non-null  float64\n 17  JalakÃ¤ija osalusel                             15563 non-null  float64\n 18  KaassÃµitja osalusel                            15563 non-null  float64\n 19  MaastikusÃµiduki juhi osalusel                  15563 non-null  float64\n 20  Eaka (65+) mootorsÃµidukijuhi osalusel          15563 non-null  float64\n 21  Bussijuhi osalusel                             15563 non-null  float64\n 22  Veoautojuhi osalusel                           15563 non-null  float64\n 23  ÃœhissÃµidukijuhi osalusel                       15563 non-null  float64\n 24  SÃµiduautojuhi osalusel                         15563 non-null  float64\n 25  Mootorratturi osalusel                         15563 non-null  float64\n 26  Mopeedijuhi osalusel                           15563 non-null  float64\n 27  Jalgratturi osalusel                           15563 non-null  float64\n 28  Alaealise osalusel                             15563 non-null  float64\n 29  Turvavarustust mitte kasutanud isiku osalusel  15563 non-null  float64\n 30  Esmase juhiloa omaniku osalusel                15563 non-null  float64\n 31  MootorsÃµidukijuhi osalusel                     15563 non-null  float64\n 32  TÃ¼Ã¼pskeemi nr                                  15245 non-null  float64\n 33  TÃ¼Ã¼pskeem [2]                                  15245 non-null  object \n 34  Tee tÃ¼Ã¼p [1]                                   15581 non-null  object \n 35  Tee tÃ¼Ã¼p [2]                                   15581 non-null  object \n 36  Tee element [1]                                15128 non-null  object \n 37  Tee element [2]                                15128 non-null  object \n 38  Tee objekt [2]                                 15169 non-null  object \n 39  Kurvilisus                                     15199 non-null  object \n 40  Tee tasasus                                    15265 non-null  object \n 41  Tee seisund                                    15310 non-null  object \n 42  Teekate                                        15406 non-null  object \n 43  Teekatte seisund [2]                           15356 non-null  object \n 44  SÃµiduradade arv                                4182 non-null   object \n 45  Lubatud sÃµidukiirus (PPA)                      15164 non-null  float64\n 46  Tee nr (PPA)                                   4749 non-null   float64\n 47  Tee km (PPA)                                   4754 non-null   object \n 48  Ilmastik [1]                                   15357 non-null  object \n 49  Valgustus [1]                                  15396 non-null  object \n 50  Valgustus [2]                                  15396 non-null  object \n 51  GPS X                                          13464 non-null  float64\n 52  GPS Y                                          13459 non-null  float64\ndtypes: float64(23), int64(2), object(28)\nmemory usage: 6.4+ MB"
  },
  {
    "objectID": "dataframes.html#section-2-polars",
    "href": "dataframes.html#section-2-polars",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "Section 2: polars",
    "text": "Section 2: polars\nPolars is a more recent dataframe library, written on top of Rust, which has been gaining a lot of traction. It uses a very different philosopy and style for the API. Both of those (being written in Rust and the API) allow it to be faster and more memory efficient than pandas. It also works out of the box with data that is too large to fit into memory.\n\n\n\n\nGetting started\nLetâ€™s redo some of the common dataframe operations we did above, using the accidents data.\n\nimport polars as pl\n\naccidents = pl.read_csv(\"data/estonia-traffic-accidents-clean.csv\")\naccidents.head()\n\n\nshape: (5, 8)\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\npedestrian_involved\naccident_type\nlight_conditions\n\n\nstr\ni64\ni64\ni64\nstr\ni64\nstr\nstr\n\n\n\n\n\"2014-10-24Â 08:45:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n1\n\"JalakÃ¤ijaÃµnnetus\"\n\"ValgeÂ aeg\"\n\n\n\"2014-10-24Â 13:45:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n0\n\"KokkupÃµrge\"\n\"ValgeÂ aeg\"\n\n\n\"2014-08-11Â 00:00:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n0\n\"KokkupÃµrge\"\n\"ValgeÂ aeg\"\n\n\n\"2014-11-17Â 17:32:00\"\n2\n0\n2\n\"HarjuÂ maakond\"\n0\n\"KokkupÃµrge\"\n\"PimedaÂ aeg\"\n\n\n\"2015-04-28Â 07:55:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n0\n\"KokkupÃµrge\"\n\"ValgeÂ aeg\"\n\n\n\n\n\n\n\n\nSome basic differences from pandas\nLike pandas, polars DataFrames are composed of Series. Youâ€™ll soon see that the API has a quite different style. Some other big differences:\n\nNo index.\nThe use of square brackets [] is discouraged, use methods instead.\nWithin reason, you want to use method chaining and do related things together, rather than splitting transformations line by line. This is so that the query optimizer can do itâ€™s thing under the hood.\nExpressions\n\nPolars also has a a doc section for Coming from Pandas.\nThe biggest conceptual difference from pandas are expressions. So letâ€™s talk about those, after a brief detour on how to select columns (since we will use that to illustrate expressions).\n\nConvert from pandas to polars and vice versa\npolars has functions for converting data frames back and forth:\n\nimport pyarrow\n\ndf = pl.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n# to make this a pandas dataframe\n# (requires pyarrow)\ndf_pd = df.to_pandas()\n# to convert it back to polars dataframe\ndf_pl = pl.DataFrame(df_pd)\n\n\n\n\nSelecting columns\nWith the select() method:\n\naccidents.select(\"date\", \"county\").head()\n\n\nshape: (5, 2)\n\n\n\ndate\ncounty\n\n\nstr\nstr\n\n\n\n\n\"2014-10-24Â 08:45:00\"\n\"HarjuÂ maakond\"\n\n\n\"2014-10-24Â 13:45:00\"\n\"HarjuÂ maakond\"\n\n\n\"2014-08-11Â 00:00:00\"\n\"HarjuÂ maakond\"\n\n\n\"2014-11-17Â 17:32:00\"\n\"HarjuÂ maakond\"\n\n\n\"2015-04-28Â 07:55:00\"\n\"HarjuÂ maakond\"\n\n\n\n\n\n\n\n\nExpressions\nPolars relies very heavily on expressions. These are data transformations that abstractly define what we want to do with some data, and operate within a context that provides data to apply those changes to actual data.\nselect() is one of the contexts in which an expression can be executed. One of the most basic expressions is pl.col(), which selects a column in the context provided. We can use this to select a column, like we did above.\n\naccidents.select(pl.col(\"date\")).head()\n\n\nshape: (5, 1)\n\n\n\ndate\n\n\nstr\n\n\n\n\n\"2014-10-24Â 08:45:00\"\n\n\n\"2014-10-24Â 13:45:00\"\n\n\n\"2014-08-11Â 00:00:00\"\n\n\n\"2014-11-17Â 17:32:00\"\n\n\n\"2015-04-28Â 07:55:00\"\n\n\n\n\n\n\n\nComposing expressions\nWhatâ€™s the point of that? By itself having a more verbose method to select columns is not that useful, but what is very useful is that we can compose expressions to do many useful things. For example:\n\n\nHow many people were injured or killed in the biggest accident in the data?\n\naccidents.select(\n    # select 'killed'\n    pl.col(\"killed\")\n    # add 'injured'\n    .add(pl.col(\"injured\"))\n    # give the result a new column name\n    .alias(\"killed_or_injured\")\n    # identify the max value\n    .max())\n\n\nshape: (1, 1)\n\n\n\nkilled_or_injured\n\n\ni64\n\n\n\n\n23\n\n\n\n\n\n\n\n\nContexts\nThere are 4 contexts in which expressions can be used:\n\nselect()\nfilter()\nwith_columns() to mutate data frames\ngroup_by() and aggregations\n\nWeâ€™ll see all of those below.\nFor more on the concept of expressions in polars, see the Expressions and contexts section in the documentation.\nFor a list of available expressions, see this more conceptual overview in the user guide, or the Python API reference on expressions.\n\n\n\nFiltering rows\nUsing filter():\n\naccidents.filter(pl.col(\"county\").eq(\"Harju maakond\")).shape\n\n(7000, 8)\n\n\n(You can generally use operators like ==, +, - as youâ€™d expect them to work, the only thing is that if you wanted to do something further with the result, youâ€™d have to wrap the calculation in extra parentheses, like (pl.col(\"a\") + pl.col(\"b\")).max(), versus pl.col(\"a\").add(pl.col(\"b\")).max().)\nAnother small example of how expressions can make life easier is below. Instead of filtering using the full county name â€œHarju maakondâ€, we can just look for strings that contain the substring â€œHarjuâ€.\n\naccidents.filter(pl.col(\"county\").str.contains(\"Harju\")).shape\n\n(7000, 8)\n\n\n\naccidents.filter(pl.col(\"county\")==\"Harju maakond\").shape\n\n(7000, 8)\n\n\n\n\nMutating dataframes\nYou use with_columns() and various expressions to mutate (add, change) columns in a dataframe. Here is how you would add a â€œkilled_or_injuredâ€ column, like we did with pandas earlier.\n\naccidents = accidents.with_columns(\n    pl.col(\"killed\").add(pl.col(\"injured\")).alias(\"killed_or_injured\")\n)\naccidents.head()\n\n\nshape: (5, 9)\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\npedestrian_involved\naccident_type\nlight_conditions\nkilled_or_injured\n\n\nstr\ni64\ni64\ni64\nstr\ni64\nstr\nstr\ni64\n\n\n\n\n\"2014-10-24Â 08:45:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n1\n\"JalakÃ¤ijaÃµnnetus\"\n\"ValgeÂ aeg\"\n1\n\n\n\"2014-10-24Â 13:45:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n0\n\"KokkupÃµrge\"\n\"ValgeÂ aeg\"\n1\n\n\n\"2014-08-11Â 00:00:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n0\n\"KokkupÃµrge\"\n\"ValgeÂ aeg\"\n1\n\n\n\"2014-11-17Â 17:32:00\"\n2\n0\n2\n\"HarjuÂ maakond\"\n0\n\"KokkupÃµrge\"\n\"PimedaÂ aeg\"\n2\n\n\n\"2015-04-28Â 07:55:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n0\n\"KokkupÃµrge\"\n\"ValgeÂ aeg\"\n1\n\n\n\n\n\n\n\n\nGroup and aggregate\nInstead of calculating the number of victims by accident type or year, as we did above, letâ€™s do by county instead.\n\nby_county = (accidents\n             .group_by(\"county\")\n             .agg(pl.col(\"killed_or_injured\").sum())\n             .sort(\"killed_or_injured\", descending=True)\n)\nby_county.head()\n\n\nshape: (5, 2)\n\n\n\ncounty\nkilled_or_injured\n\n\nstr\ni64\n\n\n\n\n\"HarjuÂ maakond\"\n8423\n\n\n\"TartuÂ maakond\"\n1968\n\n\n\"Ida-ViruÂ maakond\"\n1348\n\n\n\"PÃ¤rnuÂ maakond\"\n1293\n\n\n\"LÃ¤Ã¤ne-ViruÂ maakond\"\n883\n\n\n\n\n\n\n\n\n(Optional) Joining dataframes\nOften you have information in different dataframes (tables) that you want to join (or merge) together. For example, what if we want to know the accident rate per capita by county? For this we can first group and aggregate to get the county-level number of accident victims, then join a table with population figures for each county.\nSince we conveniently already have county-level data from above, we just need to read and join in the county population data.\n(Data are from Statistics Estonia)\n\ncounty_pop = (pl.read_csv(\"data/county-pop.csv\", skip_rows=2)\n              .rename({\"County\": \"county\", \"Age groups total\": \"population\"})\n              .select([\"county\", \"population\"])\n              # this has \"county\" in the county names, not \"maakond\"\n              .with_columns(pl.col(\"county\").str.replace(\"county\", \"maakond\"))\n              )\n\nby_county_w_pop = by_county.join(county_pop, on=\"county\", how=\"left\")\nby_county_w_pop\n\n\nshape: (15, 3)\n\n\n\ncounty\nkilled_or_injured\npopulation\n\n\nstr\ni64\ni64\n\n\n\n\n\"HarjuÂ maakond\"\n8423\n598059\n\n\n\"TartuÂ maakond\"\n1968\n152977\n\n\n\"Ida-ViruÂ maakond\"\n1348\n136240\n\n\n\"PÃ¤rnuÂ maakond\"\n1293\n85938\n\n\n\"LÃ¤Ã¤ne-ViruÂ maakond\"\n883\n59325\n\n\nâ€¦\nâ€¦\nâ€¦\n\n\n\"SaareÂ maakond\"\n413\n33108\n\n\n\"ValgaÂ maakond\"\n400\n28370\n\n\n\"PÃµlvaÂ maakond\"\n383\n25006\n\n\n\"LÃ¤Ã¤neÂ maakond\"\n272\n20507\n\n\n\"HiiuÂ maakond\"\n76\n9387\n\n\n\n\n\n\n\nby_county_w_pop.select(\n    pl.col(\"county\"), \n    pl.col(\"killed_or_injured\"),\n    pl.col(\"killed_or_injured\").truediv(pl.col(\"population\")).mul(1000).alias(\"rate/1000\")\n    ).head(3)\n\n\nshape: (3, 3)\n\n\n\ncounty\nkilled_or_injured\nrate/1000\n\n\nstr\ni64\nf64\n\n\n\n\n\"HarjuÂ maakond\"\n8423\n14.083895\n\n\n\"TartuÂ maakond\"\n1968\n12.864679\n\n\n\"Ida-ViruÂ maakond\"\n1348\n9.894304\n\n\n\n\n\n\nWhich 3 counties have the highest vehicle accident victim rates?\n\n# Add your code here\n\nWhich 3 counties have the lowest vehicle accident victim rates?\n\n# Add your code here\n\n\n\n(Optional) Reshaping / pivoting dataframes\nFor this we will look at another dataset, on reflector usage. (ğŸŒƒğŸ„ Tisâ€™ the time of yearâ€¦)\n\nreflectors = (pl.read_csv(\"data/reflectors.csv\", has_header=True, separator=\";\", skip_rows=2)\n              .filter(pl.col(\"Sex\").ne(\"Men and women\"))\n              .drop([\"Type of data\", \"Year\", \"All age groups (16-64)\"])\n)\nreflectors.head()\n\n\nshape: (5, 7)\n\n\n\nReflector use\nSex\n16-24\n25-34\n35-44\n45-54\n55-64\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"Never\"\n\"Men\"\n14.3\n12.4\n7.2\n3.9\n2.7\n\n\n\"Never\"\n\"Women\"\n8.8\n5.0\n4.6\n2.0\n2.5\n\n\n\"Sometimes\"\n\"Men\"\n46.7\n36.2\n30.9\n26.1\n28.7\n\n\n\"Sometimes\"\n\"Women\"\n29.6\n26.0\n20.6\n14.8\n13.7\n\n\n\"NearlyÂ always\"\n\"Men\"\n34.3\n40.5\n52.2\n58.6\n55.9\n\n\n\n\n\n\nAfter some basic cleaning, we can see that this dataframe has a not uncommon pattern, time series represented as rows, not columns, with their ID label as the column name. Thatâ€™s fine for presentation purposes when you look at the table, but for plotting life will be easier if we reshape this data from the current wide format to a long format.\nWe want to create two new columns from all the â€œ16-24â€ etc. columns:\n\nOne with the age group information.\nThe other with the reflector usage values.\n\n\nreflectors = (reflectors\n              .unpivot(index=[\"Reflector use\", \"Sex\"], \n                       variable_name=\"age_group\", \n                       value_name=\"percentage\")\n)\nreflectors.head()\n\n\nshape: (5, 4)\n\n\n\nReflector use\nSex\nage_group\npercentage\n\n\nstr\nstr\nstr\nf64\n\n\n\n\n\"Never\"\n\"Men\"\n\"16-24\"\n14.3\n\n\n\"Never\"\n\"Women\"\n\"16-24\"\n8.8\n\n\n\"Sometimes\"\n\"Men\"\n\"16-24\"\n46.7\n\n\n\"Sometimes\"\n\"Women\"\n\"16-24\"\n29.6\n\n\n\"NearlyÂ always\"\n\"Men\"\n\"16-24\"\n34.3\n\n\n\n\n\n\n\n(reflectors\n .filter(pl.col(\"Reflector use\").eq(\"Never\"))\n .plot.line(x = \"age_group\", y = \"percentage\", color = \"Sex\")\n .properties(\n    width=600,\n    height=300\n    )\n)\n\n\n\n\n\n\n\nClassic. Men donâ€™t wear reflectors as much as women. Old people are less likely to say that they never wear reflectors.\nActually Iâ€™m not sure who in Estonia lives in a place where they can only walk on well-lit streets. Letâ€™s combine that category with â€œNeverâ€.\n\n(reflectors.\n with_columns(\n     pl.col(\"Reflector use\").str.replace(\"Never walk on dark streets, roads\", \"Never\")\n )\n .group_by([\"Reflector use\", \"Sex\", \"age_group\"])\n .agg(pl.col(\"percentage\").sum())\n .filter(pl.col(\"Reflector use\").eq(\"Never\"))\n .sort([\"age_group\", \"Sex\"])\n .plot.line(x = \"age_group\", y = \"percentage\", color = \"Sex\")\n .properties(\n    width=600,\n    height=300\n    )\n)\n\n\n\n\n\n\n\nHmm. Maybe some people really donâ€™t walk a lot, but itâ€™s also likely that a lot of people, especially older people, donâ€™t see the need to wear reflectors.\n\nSidebar on terminology\nThere is a plethora of names to refer to the two basic directions of data reshaping.\nFor wide to long, like we did here, polars uses unpivot(), pandas calls it melt(), and Râ€™s dplyr calls itâ€¦pivot_longer().\nFor the opposite, long to wider, polars and pandas both use pivot(), while Râ€™s dplyr calls it pivot_sider(). Itâ€™s sometimes also referred to as â€œcastâ€.\nTo make things supremely confusing, spreadsheet software like Excel or Google Sheets also has the concept of a pivot table, which doesnâ€™t just pivot, but also summarizes data values. Unlike what we are doing here, where we are only changing the shape of our data, not values themselves.\n\n\n\n(Optional) LazyFrames and bigger than memory data\nAside from regular DataFrames, polars also has the concept of LazyFrames. These are abstract dataframes from some external source that are not read into memory (materialized) until you do something with them. And depending on what you do with them, this sometimes means that you can work with larger than memory datasets.\nWeâ€™re not going to work with a 30GB dataset here, so letâ€™s just illustrate the intitution here with some code:\nsmaller_data = (pl.scan_csv(\"huge/datafile.csv\")\n                .select(\"id1\", \"x1\", \"x2\")\n                .filter(pl.col(\"id1\") &gt; 100)\n                .collect())\nWhat this does is read data from a CSV, select 3 columns, and filter rows based on â€œid1â€ being greater than 100.\nThere are two key bits here:\n\npl.scan_csv(): unlike read_csv(), this does not immediately read the entire data into memory, but rather streams itâ€¦and only once we tell it to.\ncollect() to indicate that we want to start executing (materializing) our query.\n\nWhat will happen with the particular code we have above is that polars will analyze our query and then applie to memory-saving optimizations:\n\nIt will only consider data that is in the 3 columns we selected.\nFrom those columns, it will only read rows (elements) that satisfy our filter condition.\n\nMore on LazyFrames and the Lazy API at the user guide."
  },
  {
    "objectID": "dataframes.html#pro-tip-always-plot-your-data",
    "href": "dataframes.html#pro-tip-always-plot-your-data",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "Pro-tip: always plot your data",
    "text": "Pro-tip: always plot your data\nSometimes your job is to pipe data from A to B, and thatâ€™s fine.\nBut if you are doing data analysis or modeling (AI, ML, â€¦), it often pays to be curious (and suspicious) about your data. Sometimes this helps you catch errors in what you are doing with the data. Othertimes it helps you reduce the â€œgarbage inâ€ part of the â€œgarbage in, garbace outâ€ equation.\nHereâ€™s a cute example some people created to make this point. We have two data sets, is there anything unusual about them?\n\ndf1 = pl.read_csv(\"data/dataset1.csv\")\ndf2 = pl.read_csv(\"data/dataset2.csv\")\n\nThe data appear to be similar. Same number of rows and columns.\n\ndf1.shape\n\n(142, 2)\n\n\n\ndf2.shape\n\n(142, 2)\n\n\nThey also have similar distributions:\n\ndf1.describe()\n\n\nshape: (9, 3)\n\n\n\nstatistic\nx\ny\n\n\nstr\nf64\nf64\n\n\n\n\n\"count\"\n142.0\n142.0\n\n\n\"null_count\"\n0.0\n0.0\n\n\n\"mean\"\n54.2661\n47.834721\n\n\n\"std\"\n16.769825\n26.939743\n\n\n\"min\"\n15.56075\n0.015119\n\n\n\"25%\"\n39.706326\n24.46783\n\n\n\"50%\"\n53.421463\n48.398346\n\n\n\"75%\"\n69.359559\n71.806616\n\n\n\"max\"\n91.639961\n97.475771\n\n\n\n\n\n\n\ndf2.describe()\n\n\nshape: (9, 3)\n\n\n\nstatistic\nx\ny\n\n\nstr\nf64\nf64\n\n\n\n\n\"count\"\n142.0\n142.0\n\n\n\"null_count\"\n0.0\n0.0\n\n\n\"mean\"\n54.263273\n47.832253\n\n\n\"std\"\n16.765142\n26.935403\n\n\n\"min\"\n22.3077\n2.9487\n\n\n\"25%\"\n44.1026\n25.2564\n\n\n\"50%\"\n53.5897\n46.0256\n\n\n\"75%\"\n64.8718\n69.1026\n\n\n\"max\"\n98.2051\n99.4872\n\n\n\n\n\n\nAs you can guess from the section heading, we should try plotting them. (If the â€œxâ€ and â€œyâ€ column names werenâ€™t hint enough by themselvesâ€¦)\n\ndf1.plot.point(\"x\", \"y\")\n\n\n\n\n\n\n\nOk, all good, looks boring.\n\ndf2.plot.point(\"x\", \"y\")\n\n\n\n\n\n\n\nAhaa! ğŸ¦–"
  },
  {
    "objectID": "dataframes.html#appendix",
    "href": "dataframes.html#appendix",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "Appendix",
    "text": "Appendix\n\nDatasaurus\nThe cute point data from the last example came from a dataset called the Datasaurus dozen, which itself was inspired by an earlier, famous statistical toy dataset, Anscombeâ€™s quartet.\nThe other 10 datasaurus plots are also here in the data, we just took out the two above to make life easier for the workshop.\n\n# split this file but just use it to make a point about also plotting data\ndatasaurus = pd.read_csv(\"data/datasaurus.csv\")\n\ndf1 = datasaurus[datasaurus[\"dataset\"] == \"away\"].drop(\"dataset\", axis=1)\ndf2 = datasaurus[datasaurus[\"dataset\"] == \"dino\"].drop(\"dataset\", axis=1)\n\ndf1.to_csv(\"data/dataset1.csv\", index=False)\ndf2.to_csv(\"data/dataset2.csv\", index=False)"
  },
  {
    "objectID": "dataframes-presentation.html#setting-up",
    "href": "dataframes-presentation.html#setting-up",
    "title": "Python dataframes with pandas and polars",
    "section": "Setting up",
    "text": "Setting up"
  },
  {
    "objectID": "dataframes-presentation.html#using-github-codespaces",
    "href": "dataframes-presentation.html#using-github-codespaces",
    "title": "Python dataframes with pandas and polars",
    "section": "Using GitHub Codespaces",
    "text": "Using GitHub Codespaces"
  },
  {
    "objectID": "dataframes-presentation.html#using-github-codespaces-1",
    "href": "dataframes-presentation.html#using-github-codespaces-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Using GitHub Codespaces",
    "text": "Using GitHub Codespaces"
  },
  {
    "objectID": "dataframes-presentation.html#bios",
    "href": "dataframes-presentation.html#bios",
    "title": "Python dataframes with pandas and polars",
    "section": "Bios",
    "text": "Bios\n\n\nAndreas Beger\n\nğŸ¢ Data Scientist, Consult.\nğŸƒâ€â™‚ï¸ğŸŒ Slow marathoner\nğŸ“ ğŸ‡©ğŸ‡ª/ğŸ‡­ğŸ‡· â†’ ğŸ‡ºğŸ‡¸ â†’ ğŸ‡ªğŸ‡ª\nğŸ“ PhD Political Science\n\n\nIsaac Chung\n\nğŸ¢ Staff Data Scientist, Wrike\nğŸŠâ€â™‚ï¸ğŸš´ğŸƒâ€â™‚ï¸ Fast triathlete\nğŸ“ ğŸ‡­ğŸ‡° â†’ ğŸ‡¨ğŸ‡¦ â†’ ğŸ‡ªğŸ‡ª\nğŸ“ MS Machine Learning\n\n\n\nğŸ We are also the PyData Tallinn co-organizers."
  },
  {
    "objectID": "dataframes-presentation.html#definition",
    "href": "dataframes-presentation.html#definition",
    "title": "Python dataframes with pandas and polars",
    "section": "Definition",
    "text": "Definition\n\n\n\nDataframes are a data type representing 2D tables\nWhere the columns have names\nUnlike matrices or arrays, columns might have different data types\nAnd the rows are identified by one or more ID variables\n\n\n\n\n\n\n\nx\ny\ngroup\n\n\n\n\n1\n2\na\n\n\n4\n7\nb\n\n\n3\n8\na\n\n\n9\n2\nb"
  },
  {
    "objectID": "dataframes-presentation.html#why",
    "href": "dataframes-presentation.html#why",
    "title": "Python dataframes with pandas and polars",
    "section": "Why?",
    "text": "Why?\n\nImagine working with tabular data if we didnâ€™t have dataframes and associated methods.\n\n\nby_rows = [\n    {\"x\": 1, \"y\": 2, \"group\": \"a\"},\n    {\"x\": 4, \"y\": 7, \"group\": \"b\"},\n    {\"x\": 3, \"y\": 8, \"group\": \"a\"},\n    {\"x\": 9, \"y\": 2, \"group\": \"b\"}\n]\n\n\n\n\n\nby_columns = {\n    \"x\": [1, 4, 3, 9],\n    \"y\": [2, 7, 8, 2],\n    \"group\": [\"a\", \"b\", \"a\", \"b\"]\n}"
  },
  {
    "objectID": "dataframes-presentation.html#common-dataframe-operations",
    "href": "dataframes-presentation.html#common-dataframe-operations",
    "title": "Python dataframes with pandas and polars",
    "section": "Common dataframe operations",
    "text": "Common dataframe operations\n\n\n\nğŸ“– âœï¸ read and write\nğŸ”¬ inspect\nğŸ›’ select columns\nğŸ” filter rows\n\n\n\nğŸ¥ª mutate, add columns\nğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ group and aggregate\nğŸ¤ join other dataframes\nğŸ§± reshape wide, long"
  },
  {
    "objectID": "dataframes-presentation.html#agenda",
    "href": "dataframes-presentation.html#agenda",
    "title": "Python dataframes with pandas and polars",
    "section": "Agenda",
    "text": "Agenda\n\n\nPrelude: setting up, what are dataframes?\n(notebook) pandas and basic dataframe concepts and operations\n(notebook) polars, retread basic and also cover more advanced operations\nThe bigger picture: pandas vs polars, other frameworks"
  },
  {
    "objectID": "dataframes-presentation.html#history",
    "href": "dataframes-presentation.html#history",
    "title": "Python dataframes with pandas and polars",
    "section": "History",
    "text": "History\n\n\n\nCreated by Wes McKinney, now at Posit PBC\nStarted in 2008\nOriginally built on top of numpy"
  },
  {
    "objectID": "dataframes-presentation.html#getting-started",
    "href": "dataframes-presentation.html#getting-started",
    "title": "Python dataframes with pandas and polars",
    "section": "Getting started",
    "text": "Getting started\n\n\nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"quarter\": [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n    \"x\": np.random.randn(12),\n    \"date\": pd.date_range(\"2024-01-01\", periods=12, freq=\"MS\")\n})\n\ndf.head()\n\n\n\n\n\n\n\n\nquarter\nx\ndate\n\n\n\n\n0\n1\n-1.140080\n2024-01-01\n\n\n1\n1\n-0.226769\n2024-02-01\n\n\n2\n1\n-1.964979\n2024-03-01\n\n\n3\n2\n-0.526330\n2024-04-01\n\n\n4\n2\n1.224439\n2024-05-01"
  },
  {
    "objectID": "dataframes-presentation.html#components-of-a-dataframe",
    "href": "dataframes-presentation.html#components-of-a-dataframe",
    "title": "Python dataframes with pandas and polars",
    "section": "Components of a dataframe",
    "text": "Components of a dataframe\n\nSeries\n\ndf.x\n\n0    -1.140080\n1    -0.226769\n2    -1.964979\n3    -0.526330\n4     1.224439\n5    -1.012823\n6     1.335487\n7     0.127692\n8    -0.643639\n9    -0.078051\n10   -2.482828\n11    0.662283\nName: x, dtype: float64\n\n\n\n\nColumns\n\ndf.columns\n\nIndex(['quarter', 'x', 'date'], dtype='object')\n\n\n\n\nIndex\n\ndf.index\n\nRangeIndex(start=0, stop=12, step=1)"
  },
  {
    "objectID": "dataframes-presentation.html#input---reading-data",
    "href": "dataframes-presentation.html#input---reading-data",
    "title": "Python dataframes with pandas and polars",
    "section": "Input - reading data",
    "text": "Input - reading data\n\n\naccidents = pd.read_csv(\"data/estonia-traffic-accidents-clean.csv\")"
  },
  {
    "objectID": "dataframes-presentation.html#inspecting",
    "href": "dataframes-presentation.html#inspecting",
    "title": "Python dataframes with pandas and polars",
    "section": "Inspecting",
    "text": "Inspecting\n\n\naccidents.shape\n\n(14259, 8)\n\n\n\n\n\naccidents.columns\n\nIndex(['date', 'persons_involved', 'killed', 'injured', 'county',\n       'pedestrian_involved', 'accident_type', 'light_conditions'],\n      dtype='object')\n\n\n\n\n\naccidents.head()\n\n\n\n\n\n\n\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\n\n\n\n\n0\n2014-10-24 08:45:00\n2\n0\n1\nHarju maakond\n\n\n1\n2014-10-24 13:45:00\n2\n0\n1\nHarju maakond\n\n\n2\n2014-08-11 00:00:00\n2\n0\n1\nHarju maakond\n\n\n3\n2014-11-17 17:32:00\n2\n0\n2\nHarju maakond\n\n\n4\n2015-04-28 07:55:00\n2\n0\n1\nHarju maakond"
  },
  {
    "objectID": "dataframes-presentation.html#inspecting-1",
    "href": "dataframes-presentation.html#inspecting-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Inspecting",
    "text": "Inspecting\n\naccidents.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14259 entries, 0 to 14258\nData columns (total 8 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   date                 14259 non-null  object\n 1   persons_involved     14259 non-null  int64 \n 2   killed               14259 non-null  int64 \n 3   injured              14259 non-null  int64 \n 4   county               14259 non-null  object\n 5   pedestrian_involved  14259 non-null  int64 \n 6   accident_type        14259 non-null  object\n 7   light_conditions     14259 non-null  object\ndtypes: int64(4), object(4)\nmemory usage: 891.3+ KB"
  },
  {
    "objectID": "dataframes-presentation.html#selecting-columns",
    "href": "dataframes-presentation.html#selecting-columns",
    "title": "Python dataframes with pandas and polars",
    "section": "Selecting columns",
    "text": "Selecting columns\nDifferent ways, one is indexing with []:\n\n\naccidents[\"date\"].head(4)\n\n0    2014-10-24 08:45:00\n1    2014-10-24 13:45:00\n2    2014-08-11 00:00:00\n3    2014-11-17 17:32:00\nName: date, dtype: object\n\n\n\n\nMultiple columns\n\n\n\naccidents[[\"date\", \"county\"]].head(4)\n\n\n\n\n\n\n\n\ndate\ncounty\n\n\n\n\n0\n2014-10-24 08:45:00\nHarju maakond\n\n\n1\n2014-10-24 13:45:00\nHarju maakond\n\n\n2\n2014-08-11 00:00:00\nHarju maakond\n\n\n3\n2014-11-17 17:32:00\nHarju maakond"
  },
  {
    "objectID": "dataframes-presentation.html#mutating-columns",
    "href": "dataframes-presentation.html#mutating-columns",
    "title": "Python dataframes with pandas and polars",
    "section": "Mutating columns",
    "text": "Mutating columns\nRight now date is stored as a string:\n\naccidents[\"date\"][0]\n\n'2014-10-24 08:45:00'\n\n\n\ntype(accidents[\"date\"][0])\n\nstr\n\n\n\n\nConvert it to proper data type:\n\naccidents[\"date\"] = pd.to_datetime(accidents[\"date\"])\ntype(accidents[\"date\"][0])\n\npandas._libs.tslibs.timestamps.Timestamp"
  },
  {
    "objectID": "dataframes-presentation.html#sidebar-pandas-series",
    "href": "dataframes-presentation.html#sidebar-pandas-series",
    "title": "Python dataframes with pandas and polars",
    "section": "Sidebar: Pandas Series",
    "text": "Sidebar: Pandas Series\n\ndates = accidents[\"date\"]\ntype(dates)\n\npandas.core.series.Series\n\n\n\n\n\nstart = accidents[\"date\"].min()\nend = accidents[\"date\"].max()\nprint(f\"First accident: {start}\\nLast accident: {end}\")\n\nFirst accident: 2011-01-05 00:00:00\nLast accident: 2021-12-31 23:45:00\n\n\n\n\n\n\naccidents[\"accident_type\"].value_counts()\n\naccident_type\nKokkupÃµrge            5605\nÃœhesÃµidukiÃµnnetus     3946\nJalakÃ¤ijaÃµnnetus      3386\nMuu liiklusÃµnnetus    1262\nTeadmata                60\nName: count, dtype: int64\n\n\n\n\nWhat if we want to know how many accidents were in Harju county?"
  },
  {
    "objectID": "dataframes-presentation.html#filtering-rows",
    "href": "dataframes-presentation.html#filtering-rows",
    "title": "Python dataframes with pandas and polars",
    "section": "Filtering rows",
    "text": "Filtering rows\n\naccidents[accidents[\"county\"] == \"Harju maakond\"].shape\n\n(7000, 8)\n\n\n\n\n\naccidents[\"county\"] == \"Harju maakond\"\n\n0         True\n1         True\n2         True\n3         True\n4         True\n         ...  \n14254    False\n14255    False\n14256     True\n14257    False\n14258    False\nName: county, Length: 14259, dtype: bool"
  },
  {
    "objectID": "dataframes-presentation.html#mutating-dataframes",
    "href": "dataframes-presentation.html#mutating-dataframes",
    "title": "Python dataframes with pandas and polars",
    "section": "Mutating dataframes",
    "text": "Mutating dataframes\n\nHow many people were harmed in accidents in total?\n\n\n\naccidents[\"killed_or_injured\"] = accidents[\"killed\"] + accidents[\"injured\"]\naccidents[['killed', 'injured', 'killed_or_injured']].head()\n\n\n\n\n\n\n\n\nkilled\ninjured\nkilled_or_injured\n\n\n\n\n0\n0\n1\n1\n\n\n1\n0\n1\n1\n\n\n2\n0\n1\n1\n\n\n3\n0\n2\n2\n\n\n4\n0\n1\n1\n\n\n\n\n\n\n\n\n\n\n\naccidents[\"killed_or_injured\"].sum()\n\nnp.int64(18021)"
  },
  {
    "objectID": "dataframes-presentation.html#grouping-and-summarizing",
    "href": "dataframes-presentation.html#grouping-and-summarizing",
    "title": "Python dataframes with pandas and polars",
    "section": "Grouping and summarizing",
    "text": "Grouping and summarizing\n\nHow many people were harmed, by accident type?\n\n\n\nby_type = accidents.groupby(\"accident_type\").agg({\"killed_or_injured\": \"sum\"})\n\n\n\n\nby_type\n\n\n\n\n\n\n\n\nkilled_or_injured\n\n\naccident_type\n\n\n\n\n\nJalakÃ¤ijaÃµnnetus\n3548\n\n\nKokkupÃµrge\n7951\n\n\nMuu liiklusÃµnnetus\n1436\n\n\nTeadmata\n70\n\n\nÃœhesÃµidukiÃµnnetus\n5016"
  },
  {
    "objectID": "dataframes-presentation.html#pandas-is-great",
    "href": "dataframes-presentation.html#pandas-is-great",
    "title": "Python dataframes with pandas and polars",
    "section": "pandas is great",
    "text": "pandas is great\n\n 2017, Wes McKinney (creator of pandas):\n\n\n\n10 Things I Hate About Pandas \n\n\n\n\nInefficient memory management, need 5-10x data size\nEager evaluation â†’ limited query planning\nNo multi-core\n\n\n\n\nhttps://wesmckinney.com/blog/apache-arrow-pandas-internals/"
  },
  {
    "objectID": "dataframes-presentation.html#history-1",
    "href": "dataframes-presentation.html#history-1",
    "title": "Python dataframes with pandas and polars",
    "section": "History",
    "text": "History\n\n\n\nCreated in 2020 by Ritchie Vink\nStructural engineer gone data scientist/engineer\nWritten in Rust\nUses Arrow as internal representation\nArrow was created by Wes McKinney in 2016!"
  },
  {
    "objectID": "dataframes-presentation.html#new-slides",
    "href": "dataframes-presentation.html#new-slides",
    "title": "Python dataframes with pandas and polars",
    "section": "new slides",
    "text": "new slides\n\nOut with indices\nOut with .loc, .iloc\nOut with [\nIn with lazy evaluation\nExpressions"
  },
  {
    "objectID": "dataframes-presentation.html#getting-started-1",
    "href": "dataframes-presentation.html#getting-started-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Getting started",
    "text": "Getting started\n\nimport polars as pl\n\naccidents = pl.read_csv(\"data/estonia-traffic-accidents-clean.csv\")\naccidents.head()\n\n\n\n\n\nshape: (5, 5)\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\n\n\nstr\ni64\ni64\ni64\nstr\n\n\n\n\n\"2014-10-24Â 08:45:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n\n\n\"2014-10-24Â 13:45:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n\n\n\"2014-08-11Â 00:00:00\"\n2\n0\n1\n\"HarjuÂ maakond\"\n\n\n\"2014-11-17Â 17:32:00\"\n2\n0\n2\n\"HarjuÂ maakond\"\n\n\n\"2015-04-28Â 07:55:00\"\n2\n0\n1\n\"HarjuÂ maakond\""
  },
  {
    "objectID": "dataframes-presentation.html#easy-to-convert-between-the-two",
    "href": "dataframes-presentation.html#easy-to-convert-between-the-two",
    "title": "Python dataframes with pandas and polars",
    "section": "Easy to convert between the two",
    "text": "Easy to convert between the two\nimport pyarrow\n\ndf = pl.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n# to make this a pandas dataframe\n# (requires pyarrow)\ndf_pd = df.to_pandas()\n# to convert it back to polars dataframe\ndf_pl = pl.DataFrame(df_pd)"
  },
  {
    "objectID": "dataframes-presentation.html#selecting-columns-1",
    "href": "dataframes-presentation.html#selecting-columns-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Selecting columns",
    "text": "Selecting columns\n\naccidents.select(\"date\", \"county\").head()\n\n\nshape: (5, 2)\n\n\n\ndate\ncounty\n\n\nstr\nstr\n\n\n\n\n\"2014-10-24Â 08:45:00\"\n\"HarjuÂ maakond\"\n\n\n\"2014-10-24Â 13:45:00\"\n\"HarjuÂ maakond\"\n\n\n\"2014-08-11Â 00:00:00\"\n\"HarjuÂ maakond\"\n\n\n\"2014-11-17Â 17:32:00\"\n\"HarjuÂ maakond\"\n\n\n\"2015-04-28Â 07:55:00\"\n\"HarjuÂ maakond\""
  },
  {
    "objectID": "dataframes-presentation.html#expressions",
    "href": "dataframes-presentation.html#expressions",
    "title": "Python dataframes with pandas and polars",
    "section": "Expressions",
    "text": "Expressions\nExpressions are abstract, composable data transformations that are executed with a context that provides data.\n\naccidents.select(pl.col(\"date\")).head()\n\n\nshape: (5, 1)\n\n\n\ndate\n\n\nstr\n\n\n\n\n\"2014-10-24Â 08:45:00\"\n\n\n\"2014-10-24Â 13:45:00\"\n\n\n\"2014-08-11Â 00:00:00\"\n\n\n\"2014-11-17Â 17:32:00\"\n\n\n\"2015-04-28Â 07:55:00\""
  },
  {
    "objectID": "dataframes-presentation.html#they-can-be-composed",
    "href": "dataframes-presentation.html#they-can-be-composed",
    "title": "Python dataframes with pandas and polars",
    "section": "They can be composed",
    "text": "They can be composed\nWhat the biggest accident, in terms of killed or injured?\n\n\naccidents.select(\n    # select 'killed'\n    pl.col(\"killed\")\n    # add 'injured'\n    .add(pl.col(\"injured\"))\n    # give the result a new column name\n    .alias(\"killed_or_injured\")\n    # identify the max value\n    .max())\n\n\nshape: (1, 1)\n\n\n\nkilled_or_injured\n\n\ni64\n\n\n\n\n23"
  },
  {
    "objectID": "dataframes-presentation.html#and-they-work-in-multiple-contexts",
    "href": "dataframes-presentation.html#and-they-work-in-multiple-contexts",
    "title": "Python dataframes with pandas and polars",
    "section": "And they work in multiple contexts",
    "text": "And they work in multiple contexts\n\nselect()\nfilter()\nwith_columns(): mutating dataframes\ngroup_by() and aggregations"
  },
  {
    "objectID": "dataframes-presentation.html#filtering-rows-1",
    "href": "dataframes-presentation.html#filtering-rows-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Filtering rows",
    "text": "Filtering rows\nHow many accidents were in Harju county?\n\naccidents.filter(pl.col(\"county\").eq(\"Harju maakond\")).shape\n\n(7000, 8)\n\n\n\n\naccidents.filter(pl.col(\"county\").str.contains(\"Harju\")).shape\n\n(7000, 8)"
  },
  {
    "objectID": "dataframes-presentation.html#mutating-dataframes-1",
    "href": "dataframes-presentation.html#mutating-dataframes-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Mutating dataframes",
    "text": "Mutating dataframes\nwith_columns() + expressions\n\n\naccidents = accidents.with_columns(\n    pl.col(\"killed\").add(pl.col(\"injured\")).alias(\"killed_or_injured\"),\n    pl.col(\"killed\").add(pl.col(\"injured\")).truediv(pl.col(\"persons_involved\")).alias(\"harmed_rate\")\n)\naccidents.select([\"date\", \"persons_involved\", \"killed_or_injured\", \"harmed_rate\"]).head(5)\n\n\nshape: (5, 4)\n\n\n\ndate\npersons_involved\nkilled_or_injured\nharmed_rate\n\n\nstr\ni64\ni64\nf64\n\n\n\n\n\"2014-10-24Â 08:45:00\"\n2\n1\n0.5\n\n\n\"2014-10-24Â 13:45:00\"\n2\n1\n0.5\n\n\n\"2014-08-11Â 00:00:00\"\n2\n1\n0.5\n\n\n\"2014-11-17Â 17:32:00\"\n2\n2\n1.0\n\n\n\"2015-04-28Â 07:55:00\"\n2\n1\n0.5"
  },
  {
    "objectID": "dataframes-presentation.html#group-and-summarizeaggregate",
    "href": "dataframes-presentation.html#group-and-summarizeaggregate",
    "title": "Python dataframes with pandas and polars",
    "section": "Group and summarize/aggregate",
    "text": "Group and summarize/aggregate\ngroup_by() + agg() or with_columns()\n\n\nby_county = (accidents\n             .group_by(\"county\")\n             .agg(pl.col(\"killed_or_injured\").sum())\n             .sort(\"killed_or_injured\", descending=True)\n)\nby_county.head()\n\n\nshape: (5, 2)\n\n\n\ncounty\nkilled_or_injured\n\n\nstr\ni64\n\n\n\n\n\"HarjuÂ maakond\"\n8423\n\n\n\"TartuÂ maakond\"\n1968\n\n\n\"Ida-ViruÂ maakond\"\n1348\n\n\n\"PÃ¤rnuÂ maakond\"\n1293\n\n\n\"LÃ¤Ã¤ne-ViruÂ maakond\"\n883"
  },
  {
    "objectID": "dataframes-presentation.html#optional-joining-dataframes",
    "href": "dataframes-presentation.html#optional-joining-dataframes",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Joining dataframes",
    "text": "(Optional) Joining dataframes\nWhatâ€™s the per capita accident victim rate?\n\n\ncounty_pop = (pl.read_csv(\"data/county-pop.csv\", skip_rows=2)\n              .rename({\"County\": \"county\", \"Age groups total\": \"population\"})\n              .select([\"county\", \"population\"])\n              # this has \"county\" in the county names, not \"maakond\"\n              .with_columns(pl.col(\"county\").str.replace(\"county\", \"maakond\"))\n              )\n\nby_county_w_pop = by_county.join(county_pop, on=\"county\", how=\"left\")\nby_county_w_pop.head(3)\n\n\nshape: (3, 3)\n\n\n\ncounty\nkilled_or_injured\npopulation\n\n\nstr\ni64\ni64\n\n\n\n\n\"HarjuÂ maakond\"\n8423\n598059\n\n\n\"TartuÂ maakond\"\n1968\n152977\n\n\n\"Ida-ViruÂ maakond\"\n1348\n136240"
  },
  {
    "objectID": "dataframes-presentation.html#optional-joining-dataframes-1",
    "href": "dataframes-presentation.html#optional-joining-dataframes-1",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Joining dataframes",
    "text": "(Optional) Joining dataframes\nNow we can use some simple select + expressions do to the math:\n\n\nby_county_w_pop.select(\n    pl.col(\"county\"), \n    pl.col(\"killed_or_injured\"),\n    pl.col(\"killed_or_injured\").truediv(pl.col(\"population\")).mul(1000).alias(\"rate/1000\")\n    ).head(3)\n\n\nshape: (3, 3)\n\n\n\ncounty\nkilled_or_injured\nrate/1000\n\n\nstr\ni64\nf64\n\n\n\n\n\"HarjuÂ maakond\"\n8423\n14.083895\n\n\n\"TartuÂ maakond\"\n1968\n12.864679\n\n\n\"Ida-ViruÂ maakond\"\n1348\n9.894304"
  },
  {
    "objectID": "dataframes-presentation.html#optional-reshaping-pivoting-dataframes",
    "href": "dataframes-presentation.html#optional-reshaping-pivoting-dataframes",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Reshaping / pivoting dataframes",
    "text": "(Optional) Reshaping / pivoting dataframes\nWeâ€™re going to use a different dataset on reflector usage for this.\n\n\nreflectors = (pl.read_csv(\"data/reflectors.csv\", has_header=True, separator=\";\", skip_rows=2)\n              .filter(pl.col(\"Sex\").ne(\"Men and women\"))\n              .drop([\"Type of data\", \"Year\", \"All age groups (16-64)\"])\n)\nreflectors.head()\n\n\nshape: (5, 7)\n\n\n\nReflector use\nSex\n16-24\n25-34\n35-44\n45-54\n55-64\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"Never\"\n\"Men\"\n14.3\n12.4\n7.2\n3.9\n2.7\n\n\n\"Never\"\n\"Women\"\n8.8\n5.0\n4.6\n2.0\n2.5\n\n\n\"Sometimes\"\n\"Men\"\n46.7\n36.2\n30.9\n26.1\n28.7\n\n\n\"Sometimes\"\n\"Women\"\n29.6\n26.0\n20.6\n14.8\n13.7\n\n\n\"NearlyÂ always\"\n\"Men\"\n34.3\n40.5\n52.2\n58.6\n55.9"
  },
  {
    "objectID": "dataframes-presentation.html#optional-reshaping-pivoting-dataframes-1",
    "href": "dataframes-presentation.html#optional-reshaping-pivoting-dataframes-1",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Reshaping / pivoting dataframes",
    "text": "(Optional) Reshaping / pivoting dataframes\n\nreflectors = (reflectors\n              .unpivot(index=[\"Reflector use\", \"Sex\"], \n                       variable_name=\"age_group\", \n                       value_name=\"percentage\")\n)\nreflectors.head()\n\n\nshape: (5, 4)\n\n\n\nReflector use\nSex\nage_group\npercentage\n\n\nstr\nstr\nstr\nf64\n\n\n\n\n\"Never\"\n\"Men\"\n\"16-24\"\n14.3\n\n\n\"Never\"\n\"Women\"\n\"16-24\"\n8.8\n\n\n\"Sometimes\"\n\"Men\"\n\"16-24\"\n46.7\n\n\n\"Sometimes\"\n\"Women\"\n\"16-24\"\n29.6\n\n\n\"NearlyÂ always\"\n\"Men\"\n\"16-24\"\n34.3"
  },
  {
    "objectID": "dataframes-presentation.html#plot-reflector-use-by-age-and-gender",
    "href": "dataframes-presentation.html#plot-reflector-use-by-age-and-gender",
    "title": "Python dataframes with pandas and polars",
    "section": "Plot reflector use by age and gender",
    "text": "Plot reflector use by age and gender\n\n(reflectors\n .filter(pl.col(\"Reflector use\").eq(\"Never\"))\n .plot.line(x = \"age_group\", y = \"percentage\", color = \"Sex\")\n .properties(width=700, height=300)\n)"
  },
  {
    "objectID": "dataframes-presentation.html#modified-plot",
    "href": "dataframes-presentation.html#modified-plot",
    "title": "Python dataframes with pandas and polars",
    "section": "Modified plot",
    "text": "Modified plot\nOne category is â€œNever walk on dark streets, roadsâ€â€¦ğŸ§\n\n\n(reflectors\n .with_columns(pl.col(\"Reflector use\").str.replace(\"Never walk on dark streets, roads\", \"Never\"))\n .group_by([\"Reflector use\", \"Sex\", \"age_group\"])\n .agg(pl.col(\"percentage\").sum())\n .filter(pl.col(\"Reflector use\").eq(\"Never\"))\n .sort([\"age_group\", \"Sex\"])\n .plot.line(x = \"age_group\", y = \"percentage\", color = \"Sex\")\n .properties(width=700, height=300)\n)"
  },
  {
    "objectID": "dataframes-presentation.html#why-you-should-plot-your-data",
    "href": "dataframes-presentation.html#why-you-should-plot-your-data",
    "title": "Python dataframes with pandas and polars",
    "section": "Why you should plot your data ğŸ˜¼",
    "text": "Why you should plot your data ğŸ˜¼\n\n\n\ndf1 = pl.read_csv(\"data/dataset1.csv\")\ndf1.shape\n\n(142, 2)\n\n\n\n\nstats = [\"mean\", \"std\", \"25%\", \"75%\"]\n(df1\n .describe()\n .filter(pl.col(\"statistic\").is_in(stats))\n)\n\n\nshape: (4, 3)\n\n\n\nstatistic\nx\ny\n\n\nstr\nf64\nf64\n\n\n\n\n\"mean\"\n54.2661\n47.834721\n\n\n\"std\"\n16.769825\n26.939743\n\n\n\"25%\"\n39.706326\n24.46783\n\n\n\"75%\"\n69.359559\n71.806616\n\n\n\n\n\n\n\n\n\ndf2 = pl.read_csv(\"data/dataset2.csv\")\ndf2.shape\n\n(142, 2)\n\n\n\n\nstats = [\"mean\", \"std\", \"25%\", \"75%\"]\n(df2\n .describe()\n .filter(pl.col(\"statistic\").is_in(stats))\n)\n\n\nshape: (4, 3)\n\n\n\nstatistic\nx\ny\n\n\nstr\nf64\nf64\n\n\n\n\n\"mean\"\n54.263273\n47.832253\n\n\n\"std\"\n16.765142\n26.935403\n\n\n\"25%\"\n44.1026\n25.2564\n\n\n\"75%\"\n64.8718\n69.1026"
  },
  {
    "objectID": "dataframes-presentation.html#why-you-should-plot-pt2",
    "href": "dataframes-presentation.html#why-you-should-plot-pt2",
    "title": "Python dataframes with pandas and polars",
    "section": "Why you should plot pt2",
    "text": "Why you should plot pt2\n\n\n\ndf1.plot.point(\"x\", \"y\")\n\n\n\n\n\n\n\n\n\ndf2.plot.point(\"x\", \"y\")\n\n\n\n\n\n\n\n\n\nğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–ğŸ¦–"
  },
  {
    "objectID": "dataframes-presentation.html#andy-is-a-polars-stan",
    "href": "dataframes-presentation.html#andy-is-a-polars-stan",
    "title": "Python dataframes with pandas and polars",
    "section": "Andy is a polars stan",
    "text": "Andy is a polars stan\n\n\n\n\n\n\n\n\n\nhttps://star-history.com/#apache/spark&pola-rs/polars&pandas-dev/pandas&narwhals-dev/narwhals&duckdb/duckdb&Date"
  },
  {
    "objectID": "dataframes-presentation.html#comparison",
    "href": "dataframes-presentation.html#comparison",
    "title": "Python dataframes with pandas and polars",
    "section": "Comparison",
    "text": "Comparison\n\n\npandas\n\nâœ… Very widely used and supported\nâœ… Stable\nâ“ More imperative, traditional API\nâŒ Inconsistent API, multiple ways of doing the same thing\n\n\npolars\n\nâœ… More consistent, functional-style API\nâœ… Faster, less memory footprint\nâœ… Works with OOM datasets out of the box\nâŒ API still changing"
  },
  {
    "objectID": "dataframes-presentation.html#other-frameworks",
    "href": "dataframes-presentation.html#other-frameworks",
    "title": "Python dataframes with pandas and polars",
    "section": "Other frameworks",
    "text": "Other frameworks\n\n\nNarwhals\nDuckDB"
  },
  {
    "objectID": "dataframes-presentation.html#thank-you",
    "href": "dataframes-presentation.html#thank-you",
    "title": "Python dataframes with pandas and polars",
    "section": "Thank you!",
    "text": "Thank you!\nScan this and let us know how we did ğŸ¤—"
  },
  {
    "objectID": "dataframes-presentation.html#open-dataframes.ipynb",
    "href": "dataframes-presentation.html#open-dataframes.ipynb",
    "title": "Python dataframes with pandas and polars",
    "section": "Open dataframes.ipynb",
    "text": "Open dataframes.ipynb"
  },
  {
    "objectID": "dataframes-presentation.html#to-just-follow-along",
    "href": "dataframes-presentation.html#to-just-follow-along",
    "title": "Python dataframes with pandas and polars",
    "section": "To just follow along",
    "text": "To just follow along"
  },
  {
    "objectID": "dataframes-presentation.html#setting-up---link-to-repo",
    "href": "dataframes-presentation.html#setting-up---link-to-repo",
    "title": "Python dataframes with pandas and polars",
    "section": "Setting up - link to repo",
    "text": "Setting up - link to repo"
  },
  {
    "objectID": "dataframes-presentation.html#while-we-wait",
    "href": "dataframes-presentation.html#while-we-wait",
    "title": "Python dataframes with pandas and polars",
    "section": "While we wait",
    "text": "While we wait\n\n\nWho has used pandas before?\npolars?\nAnother data framework in Python, e.g.Â database + SQL?\nDoes code like this mean anything to you?\ntitanic %&gt;% \n  select(Pclass, Survived) %&gt;% \n  group_by(Pclass) %&gt;% \n  summarize(passengers = n(), surv_rate = mean(Survived))"
  },
  {
    "objectID": "dataframes-presentation.html#optional-cleaning-the-accidents-data",
    "href": "dataframes-presentation.html#optional-cleaning-the-accidents-data",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Cleaning the accidents data",
    "text": "(Optional) Cleaning the accidents data\nSee notebook."
  },
  {
    "objectID": "dataframes-presentation.html#optional-more-on-indices",
    "href": "dataframes-presentation.html#optional-more-on-indices",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) More on indices",
    "text": "(Optional) More on indices\nSee notebook."
  },
  {
    "objectID": "dataframes-presentation.html#polars-is-different-from-pandas",
    "href": "dataframes-presentation.html#polars-is-different-from-pandas",
    "title": "Python dataframes with pandas and polars",
    "section": "polars is different from pandas",
    "text": "polars is different from pandas\n\n\nUse methods, not []; no index\nCompose methods (methods chaining)\nExpressions\n\n\n\nimport pyarrow\n\ndf = pl.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n# to make this a pandas dataframe\n# (requires pyarrow)\ndf_pd = df.to_pandas()\n# to convert it back to polars dataframe\ndf_pl = pl.DataFrame(df_pd)"
  }
]