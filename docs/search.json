[
  {
    "objectID": "dataframes.html",
    "href": "dataframes.html",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "",
    "text": "Andreas Beger and Isaac Chung\nPython Code Club x PyData Tallinn\n27 November 2024\nThe source code for this notebook is github.com/andybega/dataframes-workshop."
  },
  {
    "objectID": "dataframes.html#section-1-pandas",
    "href": "dataframes.html#section-1-pandas",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "Section 1: pandas",
    "text": "Section 1: pandas\nWe will start with pandas, the original and most widely used dataframe and data analysis library in Python.\n\n\n\n\nGetting Started\nWe first need to import pandas. We’ll also import another package, numpy, which implements data types for vectors and matrices. Pandas is built on top of numpy, but we only import it here to make it easier to generate an example data frame.\n\nimport numpy as np\nimport pandas as pd\n\n# Create an example data frame\ndf = pd.DataFrame({\n    \"quarter\": [1, 1, 2, 2, 3],\n    \"x\": np.random.randn(5),\n    \"date\": pd.date_range(\"2024-01-01\", periods=5, freq=\"MS\")\n})\n\ndf\n\n\n\n\n\n\n\n\nquarter\nx\ndate\n\n\n\n\n0\n1\n-0.522780\n2024-01-01\n\n\n1\n1\n1.826809\n2024-02-01\n\n\n2\n2\n-0.487441\n2024-03-01\n\n\n3\n2\n-0.526952\n2024-04-01\n\n\n4\n3\n-1.570983\n2024-05-01\n\n\n\n\n\n\n\n\n\nComponents of a dataframe\nPandas DataFrames consist of three components:\n\nOne or more Series, which are the columns in the DataFrame.\nThe names for the series, i.e. column names of the dataframe.\nThe row names for each row in the dataframe, which pandas calls the Index.\n\n\nSeries\n\ndf.x\n\n0   -0.522780\n1    1.826809\n2   -0.487441\n3   -0.526952\n4   -1.570983\nName: x, dtype: float64\n\n\n(Note how each series can have a different data type, unlike in a matrix or an array.)\n\n\nColumns\n\ndf.columns\n\nIndex(['quarter', 'x', 'date'], dtype='object')\n\n\n\n\nIndex\n\ndf.index\n\nRangeIndex(start=0, stop=5, step=1)\n\n\nSince we didn’t explicitly set an index when we created the dataframe, it’s just a sequence of numbers starting at 0. Indexes are actually a key concept in pandas and we’ll talk a little bit more about them later.\n\n\n\nInput: reading data from elsewhere\nPandas can import dataframes from a variety of external sources like text files, JSON, Excel spreadsheets, APIs, and SQL databases. See the input/output documentation for more information.\nWe’re going to read data on Estonian vehicle accidents from a comma-separated variable (CSV) file, one of the most common text file types for storing data.\n(The accidents data are from the Estonian open data portal.)\n\naccidents = pd.read_csv(\"data/estonia-traffic-accidents-clean.csv\")\n\n\n\nInspecting\nOne of the first things we might want to do with a new dataset is to get our bearings on some basic characteristics of the data.\n\nHow many rows and columns are there?\n\naccidents.shape\n\n(14259, 8)\n\n\n\n\nWhat are the column names?\n\naccidents.columns\n\nIndex(['date', 'persons_involved', 'killed', 'injured', 'county',\n       'pedestrian_involved', 'accident_type', 'light_conditions'],\n      dtype='object')\n\n\n\n\nWhat does the data look like?\n\naccidents.head()\n\n\n\n\n\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\npedestrian_involved\naccident_type\nlight_conditions\n\n\n\n\n0\n2014-10-24 08:45:00\n2\n0\n1\nHarju maakond\n1\nJalakäijaõnnetus\nValge aeg\n\n\n1\n2014-10-24 13:45:00\n2\n0\n1\nHarju maakond\n0\nKokkupõrge\nValge aeg\n\n\n2\n2014-08-11 00:00:00\n2\n0\n1\nHarju maakond\n0\nKokkupõrge\nValge aeg\n\n\n3\n2014-11-17 17:32:00\n2\n0\n2\nHarju maakond\n0\nKokkupõrge\nPimeda aeg\n\n\n4\n2015-04-28 07:55:00\n2\n0\n1\nHarju maakond\n0\nKokkupõrge\nValge aeg\n\n\n\n\n\n\n\n\n\nDo we have missing data? What are the data types?\n\naccidents.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14259 entries, 0 to 14258\nData columns (total 8 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   date                 14259 non-null  object\n 1   persons_involved     14259 non-null  int64 \n 2   killed               14259 non-null  int64 \n 3   injured              14259 non-null  int64 \n 4   county               14259 non-null  object\n 5   pedestrian_involved  14259 non-null  int64 \n 6   accident_type        14259 non-null  object\n 7   light_conditions     14259 non-null  object\ndtypes: int64(4), object(4)\nmemory usage: 891.3+ KB\n\n\nWe could also have used accidents.dtypes to get the data types.\nNote that, if you look back at the number of rows we looked up before, you’ll notice that none of the columns have missing values, and that all but one of the data types look correct. This is because this is an already cleaned up version of the data. Below in this notebook you can also see what we did to clean up the data.\n\n\n\nSelecting columns\nThere are various ways to do this, including the &lt;dataframe&gt;.&lt;column&gt; notation we used above. One alternative is the square bracket &lt;dataframe&gt;.[]:\n\naccidents[\"date\"].head()\n\n0    2014-10-24 08:45:00\n1    2014-10-24 13:45:00\n2    2014-08-11 00:00:00\n3    2014-11-17 17:32:00\n4    2015-04-28 07:55:00\nName: date, dtype: object\n\n\nTo select multiple columns we can use a list with the column names as the argument:\n\naccidents[[\"date\", \"county\"]].head()\n\n\n\n\n\n\n\n\ndate\ncounty\n\n\n\n\n0\n2014-10-24 08:45:00\nHarju maakond\n\n\n1\n2014-10-24 13:45:00\nHarju maakond\n\n\n2\n2014-08-11 00:00:00\nHarju maakond\n\n\n3\n2014-11-17 17:32:00\nHarju maakond\n\n\n4\n2015-04-28 07:55:00\nHarju maakond\n\n\n\n\n\n\n\n\n\nMutating columns\nThe dateas are currently stored as strings (object). We should fix that.\n(pandas uses the object data types by default for strings, even though this can store arbitrary Python objects. This is for historical reasons related to originally being built on top of numpy. More on pandas text data types.)\n\naccidents[\"date\"][0]\n\n'2014-10-24 08:45:00'\n\n\n\ntype(accidents[\"date\"][0])\n\nstr\n\n\n\naccidents[\"date\"] = pd.to_datetime(accidents[\"date\"])\naccidents[\"date\"][0]\n\nTimestamp('2014-10-24 08:45:00')\n\n\n\n\nSidebar: Pandas Series\nLet’s spend a hot second looking at an individual series.\n\ndates = accidents[\"date\"]\ntype(dates)\n\npandas.core.series.Series\n\n\n\nWhat date range does the data cover?\nSeries have their own methods…\n\nstart = accidents[\"date\"].min()\nend = accidents[\"date\"].max()\nprint(f\"First accident: {start}\\nLast accident: {end}\")\n\nFirst accident: 2011-01-05 00:00:00\nLast accident: 2021-12-31 23:45:00\n\n\n\n\nWhat types of accidents were there?\nThe Series.value_counts() method is a quite useful method for tabulating categorical variables:\n\naccidents[\"accident_type\"].value_counts()\n\naccident_type\nKokkupõrge            5605\nÜhesõidukiõnnetus     3946\nJalakäijaõnnetus      3386\nMuu liiklusõnnetus    1262\nTeadmata                60\nName: count, dtype: int64\n\n\n\n\nFilter rows\nOftentimes we don’t need all rows in a dataframe to answer a specific question. This is commonly called filtering or subsetting rows.\n\n\nHow many of the accidents were in Harju county?\nWe have a “county” column, so we can use that to look at only Harju county. As with selecting columns, there are multiple ways to do this in pandas. One of the basic ones is to again use the &lt;dataframe&gt;.[] square brackets.\n\n\naccidents[accidents[\"county\"] == \"Harju maakond\"].shape\n\n(7000, 8)\n\n\nAnother sidebar – Why does this work? The part inside the outer square brackets creates a boolean vector:\n\naccidents[\"county\"] == \"Harju maakond\"\n\n0         True\n1         True\n2         True\n3         True\n4         True\n         ...  \n14254    False\n14255    False\n14256     True\n14257    False\n14258    False\nName: county, Length: 14259, dtype: bool\n\n\nWhen we pass this boolean vector to the square brackets, it uses it to filter rows. Rather than select columns, like it did with `accidents[“county”].\nYeah, it’s weird and inconsistent, which is one of the things people complain about with pandas.\nWhat’s more, there are many more ways to select and filter. See the “Indexing and selecting data” documentation for all the various methods pandas has, both for column selecting and row filtering.\n\n\n\nMutate: add a new column\nWe’ve covered how to alter an existing column. We can actually use the same method to add a new column.\n\nHow many people were killed or injured, overall?\n\naccidents[\"killed_or_injured\"] = accidents[\"killed\"] + accidents[\"injured\"]\n\naccidents[['killed', 'injured', 'killed_or_injured']].head()\n\n\n\n\n\n\n\n\nkilled\ninjured\nkilled_or_injured\n\n\n\n\n0\n0\n1\n1\n\n\n1\n0\n1\n1\n\n\n2\n0\n1\n1\n\n\n3\n0\n2\n2\n\n\n4\n0\n1\n1\n\n\n\n\n\n\n\n\naccidents[\"killed_or_injured\"].sum()\n\nnp.int64(18021)\n\n\n\n\n\nGroup and summarize\nOftentimes we want to summarize our data over some group that is defined by one of the variables. To do this we usually want to use a combination of groupby and agg.\n\nHow many people were harmed, by accident type?\n\n# summarize total accidents by something\nby_type = accidents.groupby(\"accident_type\").agg({\"killed_or_injured\": \"sum\"})\nby_type\n\n\n\n\n\n\n\n\nkilled_or_injured\n\n\naccident_type\n\n\n\n\n\nJalakäijaõnnetus\n3548\n\n\nKokkupõrge\n7951\n\n\nMuu liiklusõnnetus\n1436\n\n\nTeadmata\n70\n\n\nÜhesõidukiõnnetus\n5016\n\n\n\n\n\n\n\n\n\n\n(Optional) More on Indexes\nIn the table above, you might noticed that the “accident_type” is now for some reason shown differently from the “killed_or_injured” variable. Indeed, if we check the columns, it’s not there anymore:\n\nby_type.columns\n\nIndex(['killed_or_injured'], dtype='object')\n\n\nWhat happened is that when we did the group by and agg, pandas moved “accident_type” to the Index.\n\nby_type.index\n\nIndex(['Jalakäijaõnnetus', 'Kokkupõrge', 'Muu liiklusõnnetus', 'Teadmata',\n       'Ühesõidukiõnnetus'],\n      dtype='object', name='accident_type')\n\n\nSince we hadn’t set an index when we imported the data from CSV, this previously was just an integer count from 0, which you can see above when we showed the first few rows of the data with head(). Now it’s “accident_type”.\npandas extensively uses indexes for various operations. There are event hierarchical MultiIndexes that consist of more than one variable.\nThere are really only two important things to know about pandas Indexes.\nFirst, there are two kinds of pandas users:\n\nThose that love indexes and use them extensively. Such index powerusers are rumored to exist, at least they say.\nPeople like me who don’t use them unless forced to.\n\nSecond, indexes are like variables, but moved to the row labels. You can move them back and forth with two functions:\n\nset_index(&lt;keys&gt;): move columns to the index;  can be a column name or list of names.\nreset_index(): move the variables in the current index back to the dataframe as columns.\n\n\nHow many people were harmed, by year?\nTo further explore this, let’s look at the number of people harmed, by year.\n\nby_year = (accidents\n           .loc[:, [\"date\", \"killed_or_injured\", \"persons_involved\"]]\n           .resample(rule=\"YE\", on=\"date\")\n           .sum()\n)\n\nby_year.head()\n\n\n\n\n\n\n\n\nkilled_or_injured\npersons_involved\n\n\ndate\n\n\n\n\n\n\n2011-12-31\n533\n722\n\n\n2012-12-31\n1713\n2289\n\n\n2013-12-31\n1714\n2271\n\n\n2014-12-31\n1758\n2429\n\n\n2015-12-31\n1773\n2859\n\n\n\n\n\n\n\nThis uses a bit more complicated code we won’t explain in more detail. .loc[] is on the of the alternative select/filter methods. resample() is like groupby() but for time series. Because the code is quite long for one line, we do something called method chaining, where we put each new method call on a new line. This requires wrapping the whole statement in parentheses.\nThe date column has been moved to the index. Since we’ve aggregated the data to yearly, it would be nice, e.g. for plotting, if we just had the years in a column, not the misleading full date times.\n\n# Move date back to a column; note how we get a new dummy 0,1,... index\nby_year = by_year.reset_index()\nby_year.head()\n\n\n\n\n\n\n\n\ndate\nkilled_or_injured\npersons_involved\n\n\n\n\n0\n2011-12-31\n533\n722\n\n\n1\n2012-12-31\n1713\n2289\n\n\n2\n2013-12-31\n1714\n2271\n\n\n3\n2014-12-31\n1758\n2429\n\n\n4\n2015-12-31\n1773\n2859\n\n\n\n\n\n\n\n\n# To extract the year from the date we can use this:\nby_year[\"date\"].dt.year.head()\n\n0    2011\n1    2012\n2    2013\n3    2014\n4    2015\nName: date, dtype: int32\n\n\n\n# Create a new column with the year\nby_year[\"year\"] = by_year[\"date\"].dt.year\n# Drop the date column; we could also do this by selecting all columns but\n# the one we want to drop, but this is more explicit\nby_year = by_year.drop(\"date\", axis=1)\n# bring year to the first position\nby_year = by_year[[\"year\", \"persons_involved\", \"killed_or_injured\"]]\nby_year\n\n\n\n\n\n\n\n\nyear\npersons_involved\nkilled_or_injured\n\n\n\n\n0\n2011\n722\n533\n\n\n1\n2012\n2289\n1713\n\n\n2\n2013\n2271\n1714\n\n\n3\n2014\n2429\n1758\n\n\n4\n2015\n2859\n1773\n\n\n5\n2016\n3171\n1874\n\n\n6\n2017\n2906\n1725\n\n\n7\n2018\n3131\n1886\n\n\n8\n2019\n2923\n1752\n\n\n9\n2020\n2577\n1592\n\n\n10\n2021\n2735\n1701\n\n\n\n\n\n\n\n\n\n\n(Optional) Cleaning the accidents data\nWe mentioned above that the accidents data is already pretty clean. That’s because we did the below to clean it up. If you’re curious about this (great!), you can add more code cells and copy/paste each segment so you can see some intermediary output as well.\n\nimport dateparser  # for fixing the raw dates\n\naccidents = pd.read_csv(\"data/estonia-traffic-accidents.csv\")\n\naccidents.head()\n\naccidents.info()\n\n# Let's only keep a couple of columns for the workshop\nkeep = [\"Toimumisaeg\", \"Isikuid\", \"Hukkunuid\", \"Vigastatuid\", \"Maakond (PPA)\",\n        \"Jalakäija osalusel\", \"Liiklusõnnetuse liik [1]\", \"Valgustus [1]\"]\naccidents = accidents[keep]\n\n# Translate the column names to English\ntranslate_columns = {\"Toimumisaeg\": \"date\", \"Isikuid\": \"persons_involved\", \n                     \"Hukkunuid\": \"killed\", \"Vigastatuid\": \"injured\", \n                     \"Maakond (PPA)\": \"county\", \n                     \"Jalakäija osalusel\": \"pedestrian_involved\", \n                     \"Liiklusõnnetuse liik [1]\": \"accident_type\", \n                     \"Valgustus [1]\": \"light_conditions\"}\naccidents = accidents.rename(columns=translate_columns)\n\n# The original dates have a mix of formats. We're going to use the dateparser\n# library to help parse these. \naccidents[\"date\"] = accidents[\"date\"].apply(lambda x: dateparser.parse(x, languages=[\"en\"]))\n\n# We've got missing data in several columns. Let's drop those rows.\n# Usually you'd want to investigate what is missing and why, but it's fine\n# for the workshop since we are just illustrating, not trying to learn anything\n# about traffic accidents. \naccidents.isna().sum()\naccidents = accidents.dropna()\n\n# Some of the columns are float but should be integer values.\naccidents = accidents.astype({\"persons_involved\": \"int64\",\n                              \"pedestrian_involved\": \"int64\"})\n\n# write out the cleaned data. \n# accidents.to_csv(\"data/estonia-traffic-accidents-clean.csv\", index=False)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 15708 entries, 0 to 15707\nData columns (total 53 columns):\n #   Column                                         Non-Null Count  Dtype  \n---  ------                                         --------------  -----  \n 0   Juhtumi nr                                     15708 non-null  object \n 1   Toimumisaeg                                    15708 non-null  object \n 2   Isikuid                                        15633 non-null  float64\n 3   Hukkunuid                                      15708 non-null  int64  \n 4   Vigastatuid                                    15708 non-null  int64  \n 5   Sõidukeid                                      15633 non-null  float64\n 6   Aadress (PPA)                                  14601 non-null  object \n 7   Maja nr (PPA)                                  6686 non-null   object \n 8   Tänav (PPA)                                    14012 non-null  object \n 9   Ristuv tänav (PPA)                             2757 non-null   object \n 10  Maakond (PPA)                                  14676 non-null  object \n 11  Omavalitsus (PPA)                              14670 non-null  object \n 12  Asustus (PPA)                                  8822 non-null   object \n 13  Asula                                          15708 non-null  object \n 14  Liiklusõnnetuse liik [1]                       15708 non-null  object \n 15  Liiklusõnnetuse liik [3]                       15708 non-null  object \n 16  Kergliikurijuhi osalusel                       15563 non-null  float64\n 17  Jalakäija osalusel                             15563 non-null  float64\n 18  Kaassõitja osalusel                            15563 non-null  float64\n 19  Maastikusõiduki juhi osalusel                  15563 non-null  float64\n 20  Eaka (65+) mootorsõidukijuhi osalusel          15563 non-null  float64\n 21  Bussijuhi osalusel                             15563 non-null  float64\n 22  Veoautojuhi osalusel                           15563 non-null  float64\n 23  Ühissõidukijuhi osalusel                       15563 non-null  float64\n 24  Sõiduautojuhi osalusel                         15563 non-null  float64\n 25  Mootorratturi osalusel                         15563 non-null  float64\n 26  Mopeedijuhi osalusel                           15563 non-null  float64\n 27  Jalgratturi osalusel                           15563 non-null  float64\n 28  Alaealise osalusel                             15563 non-null  float64\n 29  Turvavarustust mitte kasutanud isiku osalusel  15563 non-null  float64\n 30  Esmase juhiloa omaniku osalusel                15563 non-null  float64\n 31  Mootorsõidukijuhi osalusel                     15563 non-null  float64\n 32  Tüüpskeemi nr                                  15245 non-null  float64\n 33  Tüüpskeem [2]                                  15245 non-null  object \n 34  Tee tüüp [1]                                   15581 non-null  object \n 35  Tee tüüp [2]                                   15581 non-null  object \n 36  Tee element [1]                                15128 non-null  object \n 37  Tee element [2]                                15128 non-null  object \n 38  Tee objekt [2]                                 15169 non-null  object \n 39  Kurvilisus                                     15199 non-null  object \n 40  Tee tasasus                                    15265 non-null  object \n 41  Tee seisund                                    15310 non-null  object \n 42  Teekate                                        15406 non-null  object \n 43  Teekatte seisund [2]                           15356 non-null  object \n 44  Sõiduradade arv                                4182 non-null   object \n 45  Lubatud sõidukiirus (PPA)                      15164 non-null  float64\n 46  Tee nr (PPA)                                   4749 non-null   float64\n 47  Tee km (PPA)                                   4754 non-null   object \n 48  Ilmastik [1]                                   15357 non-null  object \n 49  Valgustus [1]                                  15396 non-null  object \n 50  Valgustus [2]                                  15396 non-null  object \n 51  GPS X                                          13464 non-null  float64\n 52  GPS Y                                          13459 non-null  float64\ndtypes: float64(23), int64(2), object(28)\nmemory usage: 6.4+ MB"
  },
  {
    "objectID": "dataframes.html#section-2-polars",
    "href": "dataframes.html#section-2-polars",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "Section 2: polars",
    "text": "Section 2: polars\nPolars is a more recent dataframe library, written on top of Rust, which has been gaining a lot of traction. It uses a very different philosopy and style for the API. Both of those (being written in Rust and the API) allow it to be faster and more memory efficient than pandas. It also works out of the box with data that is too large to fit into memory.\n\n\n\n\nGetting started\nLet’s redo some of the common dataframe operations we did above, using the accidents data.\n\nimport polars as pl\n\naccidents = pl.read_csv(\"data/estonia-traffic-accidents-clean.csv\")\naccidents.head()\n\n\nshape: (5, 8)\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\npedestrian_involved\naccident_type\nlight_conditions\n\n\nstr\ni64\ni64\ni64\nstr\ni64\nstr\nstr\n\n\n\n\n\"2014-10-24 08:45:00\"\n2\n0\n1\n\"Harju maakond\"\n1\n\"Jalakäijaõnnetus\"\n\"Valge aeg\"\n\n\n\"2014-10-24 13:45:00\"\n2\n0\n1\n\"Harju maakond\"\n0\n\"Kokkupõrge\"\n\"Valge aeg\"\n\n\n\"2014-08-11 00:00:00\"\n2\n0\n1\n\"Harju maakond\"\n0\n\"Kokkupõrge\"\n\"Valge aeg\"\n\n\n\"2014-11-17 17:32:00\"\n2\n0\n2\n\"Harju maakond\"\n0\n\"Kokkupõrge\"\n\"Pimeda aeg\"\n\n\n\"2015-04-28 07:55:00\"\n2\n0\n1\n\"Harju maakond\"\n0\n\"Kokkupõrge\"\n\"Valge aeg\"\n\n\n\n\n\n\n\n\nSome basic differences from pandas\nLike pandas, polars DataFrames are composed of Series. You’ll soon see that the API has a quite different style. Some other big differences:\n\nNo index.\nThe use of square brackets [] is discouraged, use methods instead.\nWithin reason, you want to use method chaining and do related things together, rather than splitting transformations line by line. This is so that the query optimizer can do it’s thing under the hood.\nExpressions\n\nPolars also has a a doc section for Coming from Pandas.\nThe biggest conceptual difference from pandas are expressions. So let’s talk about those, after a brief detour on how to select columns (since we will use that to illustrate expressions).\n\nConvert from pandas to polars and vice versa\npolars has functions for converting data frames back and forth:\n\nimport pyarrow\n\ndf = pl.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n# to make this a pandas dataframe\n# (requires pyarrow)\ndf_pd = df.to_pandas()\n# to convert it back to polars dataframe\ndf_pl = pl.DataFrame(df_pd)\n\n\n\n\nSelecting columns\nWith the select() method:\n\naccidents.select(\"date\", \"county\").head()\n\n\nshape: (5, 2)\n\n\n\ndate\ncounty\n\n\nstr\nstr\n\n\n\n\n\"2014-10-24 08:45:00\"\n\"Harju maakond\"\n\n\n\"2014-10-24 13:45:00\"\n\"Harju maakond\"\n\n\n\"2014-08-11 00:00:00\"\n\"Harju maakond\"\n\n\n\"2014-11-17 17:32:00\"\n\"Harju maakond\"\n\n\n\"2015-04-28 07:55:00\"\n\"Harju maakond\"\n\n\n\n\n\n\n\n\nExpressions\nPolars relies very heavily on expressions. These are data transformations that abstractly define what we want to do with some data, and operate within a context that provides data to apply those changes to actual data.\nselect() is one of the contexts in which an expression can be executed. One of the most basic expressions is pl.col(), which selects a column in the context provided. We can use this to select a column, like we did above.\n\naccidents.select(pl.col(\"date\")).head()\n\n\nshape: (5, 1)\n\n\n\ndate\n\n\nstr\n\n\n\n\n\"2014-10-24 08:45:00\"\n\n\n\"2014-10-24 13:45:00\"\n\n\n\"2014-08-11 00:00:00\"\n\n\n\"2014-11-17 17:32:00\"\n\n\n\"2015-04-28 07:55:00\"\n\n\n\n\n\n\n\nComposing expressions\nWhat’s the point of that? By itself having a more verbose method to select columns is not that useful, but what is very useful is that we can compose expressions to do many useful things. For example:\n\n\nHow many people were injured or killed in the biggest accident in the data?\n\naccidents.select(\n    # select 'killed'\n    pl.col(\"killed\")\n    # add 'injured'\n    .add(pl.col(\"injured\"))\n    # give the result a new column name\n    .alias(\"killed_or_injured\")\n    # identify the max value\n    .max())\n\n\nshape: (1, 1)\n\n\n\nkilled_or_injured\n\n\ni64\n\n\n\n\n23\n\n\n\n\n\n\n\n\nContexts\nThere are 4 contexts in which expressions can be used:\n\nselect()\nfilter()\nwith_columns() to mutate data frames\ngroup_by() and aggregations\n\nWe’ll see all of those below.\nFor more on the concept of expressions in polars, see the Expressions and contexts section in the documentation.\nFor a list of available expressions, see this more conceptual overview in the user guide, or the Python API reference on expressions.\n\n\n\nFiltering rows\nUsing filter():\n\naccidents.filter(pl.col(\"county\").eq(\"Harju maakond\")).shape\n\n(7000, 8)\n\n\n(You can generally use operators like ==, +, - as you’d expect them to work, the only thing is that if you wanted to do something further with the result, you’d have to wrap the calculation in extra parentheses, like (pl.col(\"a\") + pl.col(\"b\")).max(), versus pl.col(\"a\").add(pl.col(\"b\")).max().)\nAnother small example of how expressions can make life easier is below. Instead of filtering using the full county name “Harju maakond”, we can just look for strings that contain the substring “Harju”.\n\naccidents.filter(pl.col(\"county\").str.contains(\"Harju\")).shape\n\n(7000, 8)\n\n\n\naccidents.filter(pl.col(\"county\")==\"Harju maakond\").shape\n\n(7000, 8)\n\n\n\n\nMutating dataframes\nYou use with_columns() and various expressions to mutate (add, change) columns in a dataframe. Here is how you would add a “killed_or_injured” column, like we did with pandas earlier.\n\naccidents = accidents.with_columns(\n    pl.col(\"killed\").add(pl.col(\"injured\")).alias(\"killed_or_injured\")\n)\naccidents.head()\n\n\nshape: (5, 9)\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\npedestrian_involved\naccident_type\nlight_conditions\nkilled_or_injured\n\n\nstr\ni64\ni64\ni64\nstr\ni64\nstr\nstr\ni64\n\n\n\n\n\"2014-10-24 08:45:00\"\n2\n0\n1\n\"Harju maakond\"\n1\n\"Jalakäijaõnnetus\"\n\"Valge aeg\"\n1\n\n\n\"2014-10-24 13:45:00\"\n2\n0\n1\n\"Harju maakond\"\n0\n\"Kokkupõrge\"\n\"Valge aeg\"\n1\n\n\n\"2014-08-11 00:00:00\"\n2\n0\n1\n\"Harju maakond\"\n0\n\"Kokkupõrge\"\n\"Valge aeg\"\n1\n\n\n\"2014-11-17 17:32:00\"\n2\n0\n2\n\"Harju maakond\"\n0\n\"Kokkupõrge\"\n\"Pimeda aeg\"\n2\n\n\n\"2015-04-28 07:55:00\"\n2\n0\n1\n\"Harju maakond\"\n0\n\"Kokkupõrge\"\n\"Valge aeg\"\n1\n\n\n\n\n\n\n\n\nGroup and aggregate\nInstead of calculating the number of victims by accident type or year, as we did above, let’s do by county instead.\n\nby_county = (accidents\n             .group_by(\"county\")\n             .agg(pl.col(\"killed_or_injured\").sum())\n             .sort(\"killed_or_injured\", descending=True)\n)\nby_county.head()\n\n\nshape: (5, 2)\n\n\n\ncounty\nkilled_or_injured\n\n\nstr\ni64\n\n\n\n\n\"Harju maakond\"\n8423\n\n\n\"Tartu maakond\"\n1968\n\n\n\"Ida-Viru maakond\"\n1348\n\n\n\"Pärnu maakond\"\n1293\n\n\n\"Lääne-Viru maakond\"\n883\n\n\n\n\n\n\n\n\n(Optional) Joining dataframes\nOften you have information in different dataframes (tables) that you want to join (or merge) together. For example, what if we want to know the accident rate per capita by county? For this we can first group and aggregate to get the county-level number of accident victims, then join a table with population figures for each county.\nSince we conveniently already have county-level data from above, we just need to read and join in the county population data.\n(Data are from Statistics Estonia)\n\ncounty_pop = (pl.read_csv(\"data/county-pop.csv\", skip_rows=2)\n              .rename({\"County\": \"county\", \"Age groups total\": \"population\"})\n              .select([\"county\", \"population\"])\n              # this has \"county\" in the county names, not \"maakond\"\n              .with_columns(pl.col(\"county\").str.replace(\"county\", \"maakond\"))\n              )\n\nby_county_w_pop = by_county.join(county_pop, on=\"county\", how=\"left\")\nby_county_w_pop\n\n\nshape: (15, 3)\n\n\n\ncounty\nkilled_or_injured\npopulation\n\n\nstr\ni64\ni64\n\n\n\n\n\"Harju maakond\"\n8423\n598059\n\n\n\"Tartu maakond\"\n1968\n152977\n\n\n\"Ida-Viru maakond\"\n1348\n136240\n\n\n\"Pärnu maakond\"\n1293\n85938\n\n\n\"Lääne-Viru maakond\"\n883\n59325\n\n\n…\n…\n…\n\n\n\"Saare maakond\"\n413\n33108\n\n\n\"Valga maakond\"\n400\n28370\n\n\n\"Põlva maakond\"\n383\n25006\n\n\n\"Lääne maakond\"\n272\n20507\n\n\n\"Hiiu maakond\"\n76\n9387\n\n\n\n\n\n\n\nby_county_w_pop.select(\n    pl.col(\"county\"), \n    pl.col(\"killed_or_injured\"),\n    pl.col(\"killed_or_injured\").truediv(pl.col(\"population\")).mul(1000).alias(\"rate/1000\")\n    ).head(3)\n\n\nshape: (3, 3)\n\n\n\ncounty\nkilled_or_injured\nrate/1000\n\n\nstr\ni64\nf64\n\n\n\n\n\"Harju maakond\"\n8423\n14.083895\n\n\n\"Tartu maakond\"\n1968\n12.864679\n\n\n\"Ida-Viru maakond\"\n1348\n9.894304\n\n\n\n\n\n\nWhich 3 counties have the highest vehicle accident victim rates?\n\n# Add your code here\n\nWhich 3 counties have the lowest vehicle accident victim rates?\n\n# Add your code here\n\n\n\n(Optional) Reshaping / pivoting dataframes\nFor this we will look at another dataset, on reflector usage. (🌃🎄 Tis’ the time of year…)\n\nreflectors = (pl.read_csv(\"data/reflectors.csv\", has_header=True, separator=\";\", skip_rows=2)\n              .filter(pl.col(\"Sex\").ne(\"Men and women\"))\n              .drop([\"Type of data\", \"Year\", \"All age groups (16-64)\"])\n)\nreflectors.head()\n\n\nshape: (5, 7)\n\n\n\nReflector use\nSex\n16-24\n25-34\n35-44\n45-54\n55-64\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"Never\"\n\"Men\"\n14.3\n12.4\n7.2\n3.9\n2.7\n\n\n\"Never\"\n\"Women\"\n8.8\n5.0\n4.6\n2.0\n2.5\n\n\n\"Sometimes\"\n\"Men\"\n46.7\n36.2\n30.9\n26.1\n28.7\n\n\n\"Sometimes\"\n\"Women\"\n29.6\n26.0\n20.6\n14.8\n13.7\n\n\n\"Nearly always\"\n\"Men\"\n34.3\n40.5\n52.2\n58.6\n55.9\n\n\n\n\n\n\nAfter some basic cleaning, we can see that this dataframe has a not uncommon pattern, time series represented as rows, not columns, with their ID label as the column name. That’s fine for presentation purposes when you look at the table, but for plotting life will be easier if we reshape this data from the current wide format to a long format.\nWe want to create two new columns from all the “16-24” etc. columns:\n\nOne with the age group information.\nThe other with the reflector usage values.\n\n\nreflectors = (reflectors\n              .unpivot(index=[\"Reflector use\", \"Sex\"], \n                       variable_name=\"age_group\", \n                       value_name=\"percentage\")\n)\nreflectors.head()\n\n\nshape: (5, 4)\n\n\n\nReflector use\nSex\nage_group\npercentage\n\n\nstr\nstr\nstr\nf64\n\n\n\n\n\"Never\"\n\"Men\"\n\"16-24\"\n14.3\n\n\n\"Never\"\n\"Women\"\n\"16-24\"\n8.8\n\n\n\"Sometimes\"\n\"Men\"\n\"16-24\"\n46.7\n\n\n\"Sometimes\"\n\"Women\"\n\"16-24\"\n29.6\n\n\n\"Nearly always\"\n\"Men\"\n\"16-24\"\n34.3\n\n\n\n\n\n\n\n(reflectors\n .filter(pl.col(\"Reflector use\").eq(\"Never\"))\n .plot.line(x = \"age_group\", y = \"percentage\", color = \"Sex\")\n .properties(\n    width=600,\n    height=300\n    )\n)\n\n\n\n\n\n\n\nClassic. Men don’t wear reflectors as much as women. Old people are less likely to say that they never wear reflectors.\nActually I’m not sure who in Estonia lives in a place where they can only walk on well-lit streets. Let’s combine that category with “Never”.\n\n(reflectors.\n with_columns(\n     pl.col(\"Reflector use\").str.replace(\"Never walk on dark streets, roads\", \"Never\")\n )\n .group_by([\"Reflector use\", \"Sex\", \"age_group\"])\n .agg(pl.col(\"percentage\").sum())\n .filter(pl.col(\"Reflector use\").eq(\"Never\"))\n .sort([\"age_group\", \"Sex\"])\n .plot.line(x = \"age_group\", y = \"percentage\", color = \"Sex\")\n .properties(\n    width=600,\n    height=300\n    )\n)\n\n\n\n\n\n\n\nHmm. Maybe some people really don’t walk a lot, but it’s also likely that a lot of people, especially older people, don’t see the need to wear reflectors.\n\nSidebar on terminology\nThere is a plethora of names to refer to the two basic directions of data reshaping.\nFor wide to long, like we did here, polars uses unpivot(), pandas calls it melt(), and R’s dplyr calls it…pivot_longer().\nFor the opposite, long to wider, polars and pandas both use pivot(), while R’s dplyr calls it pivot_sider(). It’s sometimes also referred to as “cast”.\nTo make things supremely confusing, spreadsheet software like Excel or Google Sheets also has the concept of a pivot table, which doesn’t just pivot, but also summarizes data values. Unlike what we are doing here, where we are only changing the shape of our data, not values themselves.\n\n\n\n(Optional) LazyFrames and bigger than memory data\nAside from regular DataFrames, polars also has the concept of LazyFrames. These are abstract dataframes from some external source that are not read into memory (materialized) until you do something with them. And depending on what you do with them, this sometimes means that you can work with larger than memory datasets.\nWe’re not going to work with a 30GB dataset here, so let’s just illustrate the intitution here with some code:\nsmaller_data = (pl.scan_csv(\"huge/datafile.csv\")\n                .select(\"id1\", \"x1\", \"x2\")\n                .filter(pl.col(\"id1\") &gt; 100)\n                .collect())\nWhat this does is read data from a CSV, select 3 columns, and filter rows based on “id1” being greater than 100.\nThere are two key bits here:\n\npl.scan_csv(): unlike read_csv(), this does not immediately read the entire data into memory, but rather streams it…and only once we tell it to.\ncollect() to indicate that we want to start executing (materializing) our query.\n\nWhat will happen with the particular code we have above is that polars will analyze our query and then applie to memory-saving optimizations:\n\nIt will only consider data that is in the 3 columns we selected.\nFrom those columns, it will only read rows (elements) that satisfy our filter condition.\n\nMore on LazyFrames and the Lazy API at the user guide."
  },
  {
    "objectID": "dataframes.html#pro-tip-always-plot-your-data",
    "href": "dataframes.html#pro-tip-always-plot-your-data",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "Pro-tip: always plot your data",
    "text": "Pro-tip: always plot your data\nSometimes your job is to pipe data from A to B, and that’s fine.\nBut if you are doing data analysis or modeling (AI, ML, …), it often pays to be curious (and suspicious) about your data. Sometimes this helps you catch errors in what you are doing with the data. Othertimes it helps you reduce the “garbage in” part of the “garbage in, garbace out” equation.\nHere’s a cute example some people created to make this point. We have two data sets, is there anything unusual about them?\n\ndf1 = pl.read_csv(\"data/dataset1.csv\")\ndf2 = pl.read_csv(\"data/dataset2.csv\")\n\nThe data appear to be similar. Same number of rows and columns.\n\ndf1.shape\n\n(142, 2)\n\n\n\ndf2.shape\n\n(142, 2)\n\n\nThey also have similar distributions:\n\ndf1.describe()\n\n\nshape: (9, 3)\n\n\n\nstatistic\nx\ny\n\n\nstr\nf64\nf64\n\n\n\n\n\"count\"\n142.0\n142.0\n\n\n\"null_count\"\n0.0\n0.0\n\n\n\"mean\"\n54.2661\n47.834721\n\n\n\"std\"\n16.769825\n26.939743\n\n\n\"min\"\n15.56075\n0.015119\n\n\n\"25%\"\n39.706326\n24.46783\n\n\n\"50%\"\n53.421463\n48.398346\n\n\n\"75%\"\n69.359559\n71.806616\n\n\n\"max\"\n91.639961\n97.475771\n\n\n\n\n\n\n\ndf2.describe()\n\n\nshape: (9, 3)\n\n\n\nstatistic\nx\ny\n\n\nstr\nf64\nf64\n\n\n\n\n\"count\"\n142.0\n142.0\n\n\n\"null_count\"\n0.0\n0.0\n\n\n\"mean\"\n54.263273\n47.832253\n\n\n\"std\"\n16.765142\n26.935403\n\n\n\"min\"\n22.3077\n2.9487\n\n\n\"25%\"\n44.1026\n25.2564\n\n\n\"50%\"\n53.5897\n46.0256\n\n\n\"75%\"\n64.8718\n69.1026\n\n\n\"max\"\n98.2051\n99.4872\n\n\n\n\n\n\nAs you can guess from the section heading, we should try plotting them. (If the “x” and “y” column names weren’t hint enough by themselves…)\n\ndf1.plot.point(\"x\", \"y\")\n\n\n\n\n\n\n\nOk, all good, looks boring.\n\ndf2.plot.point(\"x\", \"y\")\n\n\n\n\n\n\n\nAhaa! 🦖"
  },
  {
    "objectID": "dataframes.html#appendix",
    "href": "dataframes.html#appendix",
    "title": "Introduction to dataframes in Python with pandas and polars",
    "section": "Appendix",
    "text": "Appendix\n\nDatasaurus\nThe cute point data from the last example came from a dataset called the Datasaurus dozen, which itself was inspired by an earlier, famous statistical toy dataset, Anscombe’s quartet.\nThe other 10 datasaurus plots are also here in the data, we just took out the two above to make life easier for the workshop.\n\n# split this file but just use it to make a point about also plotting data\ndatasaurus = pd.read_csv(\"data/datasaurus.csv\")\n\ndf1 = datasaurus[datasaurus[\"dataset\"] == \"away\"].drop(\"dataset\", axis=1)\ndf2 = datasaurus[datasaurus[\"dataset\"] == \"dino\"].drop(\"dataset\", axis=1)\n\ndf1.to_csv(\"data/dataset1.csv\", index=False)\ndf2.to_csv(\"data/dataset2.csv\", index=False)"
  },
  {
    "objectID": "dataframes-presentation.html#setting-up",
    "href": "dataframes-presentation.html#setting-up",
    "title": "Python dataframes with pandas and polars",
    "section": "Setting up",
    "text": "Setting up"
  },
  {
    "objectID": "dataframes-presentation.html#using-github-codespaces",
    "href": "dataframes-presentation.html#using-github-codespaces",
    "title": "Python dataframes with pandas and polars",
    "section": "Using GitHub Codespaces",
    "text": "Using GitHub Codespaces"
  },
  {
    "objectID": "dataframes-presentation.html#using-github-codespaces-1",
    "href": "dataframes-presentation.html#using-github-codespaces-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Using GitHub Codespaces",
    "text": "Using GitHub Codespaces"
  },
  {
    "objectID": "dataframes-presentation.html#bios",
    "href": "dataframes-presentation.html#bios",
    "title": "Python dataframes with pandas and polars",
    "section": "Bios",
    "text": "Bios\n\n\nAndreas Beger\n\n🏢 Data Scientist, Consult.\n🏃‍♂️🐌 Slow marathoner\n📍 🇩🇪/🇭🇷 → 🇺🇸 → 🇪🇪\n🎓 PhD Political Science\n\n\nIsaac Chung\n\n🏢 Staff Data Scientist, Wrike\n🏊‍♂️🚴🏃‍♂️ Fast triathlete\n📍 🇭🇰 → 🇨🇦 → 🇪🇪\n🎓 MS Machine Learning\n\n\n\n🐍 We are also the PyData Tallinn co-organizers."
  },
  {
    "objectID": "dataframes-presentation.html#definition",
    "href": "dataframes-presentation.html#definition",
    "title": "Python dataframes with pandas and polars",
    "section": "Definition",
    "text": "Definition\n\n\n\nDataframes are a data type representing 2D tables\nWhere the columns have names\nUnlike matrices or arrays, columns might have different data types\nAnd the rows are identified by one or more ID variables\n\n\n\n\n\n\n\nx\ny\ngroup\n\n\n\n\n1\n2\na\n\n\n4\n7\nb\n\n\n3\n8\na\n\n\n9\n2\nb"
  },
  {
    "objectID": "dataframes-presentation.html#why",
    "href": "dataframes-presentation.html#why",
    "title": "Python dataframes with pandas and polars",
    "section": "Why?",
    "text": "Why?\n\nImagine working with tabular data if we didn’t have dataframes and associated methods.\n\n\nby_rows = [\n    {\"x\": 1, \"y\": 2, \"group\": \"a\"},\n    {\"x\": 4, \"y\": 7, \"group\": \"b\"},\n    {\"x\": 3, \"y\": 8, \"group\": \"a\"},\n    {\"x\": 9, \"y\": 2, \"group\": \"b\"}\n]\n\n\n\n\n\nby_columns = {\n    \"x\": [1, 4, 3, 9],\n    \"y\": [2, 7, 8, 2],\n    \"group\": [\"a\", \"b\", \"a\", \"b\"]\n}"
  },
  {
    "objectID": "dataframes-presentation.html#common-dataframe-operations",
    "href": "dataframes-presentation.html#common-dataframe-operations",
    "title": "Python dataframes with pandas and polars",
    "section": "Common dataframe operations",
    "text": "Common dataframe operations\n\n\n\n📖 ✍️ read and write\n🔬 inspect\n🛒 select columns\n🔍 filter rows\n\n\n\n🥪 mutate, add columns\n👨‍👩‍👧‍👦 group and aggregate\n🤝 join other dataframes\n🧱 reshape wide, long"
  },
  {
    "objectID": "dataframes-presentation.html#agenda",
    "href": "dataframes-presentation.html#agenda",
    "title": "Python dataframes with pandas and polars",
    "section": "Agenda",
    "text": "Agenda\n\n\nPrelude: setting up, what are dataframes?\n(notebook) pandas and basic dataframe concepts and operations\n(notebook) polars, retread basic and also cover more advanced operations\nThe bigger picture: pandas vs polars, other frameworks"
  },
  {
    "objectID": "dataframes-presentation.html#history",
    "href": "dataframes-presentation.html#history",
    "title": "Python dataframes with pandas and polars",
    "section": "History",
    "text": "History\n\n\n\nCreated by Wes McKinney, now at Posit PBC\nStarted in 2008\nOriginally built on top of numpy"
  },
  {
    "objectID": "dataframes-presentation.html#getting-started",
    "href": "dataframes-presentation.html#getting-started",
    "title": "Python dataframes with pandas and polars",
    "section": "Getting started",
    "text": "Getting started\n\n\nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"quarter\": [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n    \"x\": np.random.randn(12),\n    \"date\": pd.date_range(\"2024-01-01\", periods=12, freq=\"MS\")\n})\n\ndf.head()\n\n\n\n\n\n\n\n\nquarter\nx\ndate\n\n\n\n\n0\n1\n-1.140080\n2024-01-01\n\n\n1\n1\n-0.226769\n2024-02-01\n\n\n2\n1\n-1.964979\n2024-03-01\n\n\n3\n2\n-0.526330\n2024-04-01\n\n\n4\n2\n1.224439\n2024-05-01"
  },
  {
    "objectID": "dataframes-presentation.html#components-of-a-dataframe",
    "href": "dataframes-presentation.html#components-of-a-dataframe",
    "title": "Python dataframes with pandas and polars",
    "section": "Components of a dataframe",
    "text": "Components of a dataframe\n\nSeries\n\ndf.x\n\n0    -1.140080\n1    -0.226769\n2    -1.964979\n3    -0.526330\n4     1.224439\n5    -1.012823\n6     1.335487\n7     0.127692\n8    -0.643639\n9    -0.078051\n10   -2.482828\n11    0.662283\nName: x, dtype: float64\n\n\n\n\nColumns\n\ndf.columns\n\nIndex(['quarter', 'x', 'date'], dtype='object')\n\n\n\n\nIndex\n\ndf.index\n\nRangeIndex(start=0, stop=12, step=1)"
  },
  {
    "objectID": "dataframes-presentation.html#input---reading-data",
    "href": "dataframes-presentation.html#input---reading-data",
    "title": "Python dataframes with pandas and polars",
    "section": "Input - reading data",
    "text": "Input - reading data\n\n\naccidents = pd.read_csv(\"data/estonia-traffic-accidents-clean.csv\")"
  },
  {
    "objectID": "dataframes-presentation.html#inspecting",
    "href": "dataframes-presentation.html#inspecting",
    "title": "Python dataframes with pandas and polars",
    "section": "Inspecting",
    "text": "Inspecting\n\n\naccidents.shape\n\n(14259, 8)\n\n\n\n\n\naccidents.columns\n\nIndex(['date', 'persons_involved', 'killed', 'injured', 'county',\n       'pedestrian_involved', 'accident_type', 'light_conditions'],\n      dtype='object')\n\n\n\n\n\naccidents.head()\n\n\n\n\n\n\n\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\n\n\n\n\n0\n2014-10-24 08:45:00\n2\n0\n1\nHarju maakond\n\n\n1\n2014-10-24 13:45:00\n2\n0\n1\nHarju maakond\n\n\n2\n2014-08-11 00:00:00\n2\n0\n1\nHarju maakond\n\n\n3\n2014-11-17 17:32:00\n2\n0\n2\nHarju maakond\n\n\n4\n2015-04-28 07:55:00\n2\n0\n1\nHarju maakond"
  },
  {
    "objectID": "dataframes-presentation.html#inspecting-1",
    "href": "dataframes-presentation.html#inspecting-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Inspecting",
    "text": "Inspecting\n\naccidents.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14259 entries, 0 to 14258\nData columns (total 8 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   date                 14259 non-null  object\n 1   persons_involved     14259 non-null  int64 \n 2   killed               14259 non-null  int64 \n 3   injured              14259 non-null  int64 \n 4   county               14259 non-null  object\n 5   pedestrian_involved  14259 non-null  int64 \n 6   accident_type        14259 non-null  object\n 7   light_conditions     14259 non-null  object\ndtypes: int64(4), object(4)\nmemory usage: 891.3+ KB"
  },
  {
    "objectID": "dataframes-presentation.html#selecting-columns",
    "href": "dataframes-presentation.html#selecting-columns",
    "title": "Python dataframes with pandas and polars",
    "section": "Selecting columns",
    "text": "Selecting columns\nDifferent ways, one is indexing with []:\n\n\naccidents[\"date\"].head(4)\n\n0    2014-10-24 08:45:00\n1    2014-10-24 13:45:00\n2    2014-08-11 00:00:00\n3    2014-11-17 17:32:00\nName: date, dtype: object\n\n\n\n\nMultiple columns\n\n\n\naccidents[[\"date\", \"county\"]].head(4)\n\n\n\n\n\n\n\n\ndate\ncounty\n\n\n\n\n0\n2014-10-24 08:45:00\nHarju maakond\n\n\n1\n2014-10-24 13:45:00\nHarju maakond\n\n\n2\n2014-08-11 00:00:00\nHarju maakond\n\n\n3\n2014-11-17 17:32:00\nHarju maakond"
  },
  {
    "objectID": "dataframes-presentation.html#mutating-columns",
    "href": "dataframes-presentation.html#mutating-columns",
    "title": "Python dataframes with pandas and polars",
    "section": "Mutating columns",
    "text": "Mutating columns\nRight now date is stored as a string:\n\naccidents[\"date\"][0]\n\n'2014-10-24 08:45:00'\n\n\n\ntype(accidents[\"date\"][0])\n\nstr\n\n\n\n\nConvert it to proper data type:\n\naccidents[\"date\"] = pd.to_datetime(accidents[\"date\"])\ntype(accidents[\"date\"][0])\n\npandas._libs.tslibs.timestamps.Timestamp"
  },
  {
    "objectID": "dataframes-presentation.html#sidebar-pandas-series",
    "href": "dataframes-presentation.html#sidebar-pandas-series",
    "title": "Python dataframes with pandas and polars",
    "section": "Sidebar: Pandas Series",
    "text": "Sidebar: Pandas Series\n\ndates = accidents[\"date\"]\ntype(dates)\n\npandas.core.series.Series\n\n\n\n\n\nstart = accidents[\"date\"].min()\nend = accidents[\"date\"].max()\nprint(f\"First accident: {start}\\nLast accident: {end}\")\n\nFirst accident: 2011-01-05 00:00:00\nLast accident: 2021-12-31 23:45:00\n\n\n\n\n\n\naccidents[\"accident_type\"].value_counts()\n\naccident_type\nKokkupõrge            5605\nÜhesõidukiõnnetus     3946\nJalakäijaõnnetus      3386\nMuu liiklusõnnetus    1262\nTeadmata                60\nName: count, dtype: int64\n\n\n\n\nWhat if we want to know how many accidents were in Harju county?"
  },
  {
    "objectID": "dataframes-presentation.html#filtering-rows",
    "href": "dataframes-presentation.html#filtering-rows",
    "title": "Python dataframes with pandas and polars",
    "section": "Filtering rows",
    "text": "Filtering rows\n\naccidents[accidents[\"county\"] == \"Harju maakond\"].shape\n\n(7000, 8)\n\n\n\n\n\naccidents[\"county\"] == \"Harju maakond\"\n\n0         True\n1         True\n2         True\n3         True\n4         True\n         ...  \n14254    False\n14255    False\n14256     True\n14257    False\n14258    False\nName: county, Length: 14259, dtype: bool"
  },
  {
    "objectID": "dataframes-presentation.html#mutating-dataframes",
    "href": "dataframes-presentation.html#mutating-dataframes",
    "title": "Python dataframes with pandas and polars",
    "section": "Mutating dataframes",
    "text": "Mutating dataframes\n\nHow many people were harmed in accidents in total?\n\n\n\naccidents[\"killed_or_injured\"] = accidents[\"killed\"] + accidents[\"injured\"]\naccidents[['killed', 'injured', 'killed_or_injured']].head()\n\n\n\n\n\n\n\n\nkilled\ninjured\nkilled_or_injured\n\n\n\n\n0\n0\n1\n1\n\n\n1\n0\n1\n1\n\n\n2\n0\n1\n1\n\n\n3\n0\n2\n2\n\n\n4\n0\n1\n1\n\n\n\n\n\n\n\n\n\n\n\naccidents[\"killed_or_injured\"].sum()\n\nnp.int64(18021)"
  },
  {
    "objectID": "dataframes-presentation.html#grouping-and-summarizing",
    "href": "dataframes-presentation.html#grouping-and-summarizing",
    "title": "Python dataframes with pandas and polars",
    "section": "Grouping and summarizing",
    "text": "Grouping and summarizing\n\nHow many people were harmed, by accident type?\n\n\n\nby_type = accidents.groupby(\"accident_type\").agg({\"killed_or_injured\": \"sum\"})\n\n\n\n\nby_type\n\n\n\n\n\n\n\n\nkilled_or_injured\n\n\naccident_type\n\n\n\n\n\nJalakäijaõnnetus\n3548\n\n\nKokkupõrge\n7951\n\n\nMuu liiklusõnnetus\n1436\n\n\nTeadmata\n70\n\n\nÜhesõidukiõnnetus\n5016"
  },
  {
    "objectID": "dataframes-presentation.html#pandas-is-great",
    "href": "dataframes-presentation.html#pandas-is-great",
    "title": "Python dataframes with pandas and polars",
    "section": "pandas is great",
    "text": "pandas is great\n\n 2017, Wes McKinney (creator of pandas):\n\n\n\n10 Things I Hate About Pandas \n\n\n\n\nInefficient memory management, need 5-10x data size\nEager evaluation → limited query planning\nNo multi-core\n\n\n\n\nhttps://wesmckinney.com/blog/apache-arrow-pandas-internals/"
  },
  {
    "objectID": "dataframes-presentation.html#history-1",
    "href": "dataframes-presentation.html#history-1",
    "title": "Python dataframes with pandas and polars",
    "section": "History",
    "text": "History\n\n\n\nCreated in 2020 by Ritchie Vink\nStructural engineer gone data scientist/engineer\nWritten in Rust\nUses Arrow as internal representation\nArrow was created by Wes McKinney in 2016!"
  },
  {
    "objectID": "dataframes-presentation.html#new-slides",
    "href": "dataframes-presentation.html#new-slides",
    "title": "Python dataframes with pandas and polars",
    "section": "new slides",
    "text": "new slides\n\nOut with indices\nOut with .loc, .iloc\nOut with [\nIn with lazy evaluation\nExpressions"
  },
  {
    "objectID": "dataframes-presentation.html#getting-started-1",
    "href": "dataframes-presentation.html#getting-started-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Getting started",
    "text": "Getting started\n\nimport polars as pl\n\naccidents = pl.read_csv(\"data/estonia-traffic-accidents-clean.csv\")\naccidents.head()\n\n\n\n\n\nshape: (5, 5)\n\n\n\ndate\npersons_involved\nkilled\ninjured\ncounty\n\n\nstr\ni64\ni64\ni64\nstr\n\n\n\n\n\"2014-10-24 08:45:00\"\n2\n0\n1\n\"Harju maakond\"\n\n\n\"2014-10-24 13:45:00\"\n2\n0\n1\n\"Harju maakond\"\n\n\n\"2014-08-11 00:00:00\"\n2\n0\n1\n\"Harju maakond\"\n\n\n\"2014-11-17 17:32:00\"\n2\n0\n2\n\"Harju maakond\"\n\n\n\"2015-04-28 07:55:00\"\n2\n0\n1\n\"Harju maakond\""
  },
  {
    "objectID": "dataframes-presentation.html#easy-to-convert-between-the-two",
    "href": "dataframes-presentation.html#easy-to-convert-between-the-two",
    "title": "Python dataframes with pandas and polars",
    "section": "Easy to convert between the two",
    "text": "Easy to convert between the two\nimport pyarrow\n\ndf = pl.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n# to make this a pandas dataframe\n# (requires pyarrow)\ndf_pd = df.to_pandas()\n# to convert it back to polars dataframe\ndf_pl = pl.DataFrame(df_pd)"
  },
  {
    "objectID": "dataframes-presentation.html#selecting-columns-1",
    "href": "dataframes-presentation.html#selecting-columns-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Selecting columns",
    "text": "Selecting columns\n\naccidents.select(\"date\", \"county\").head()\n\n\nshape: (5, 2)\n\n\n\ndate\ncounty\n\n\nstr\nstr\n\n\n\n\n\"2014-10-24 08:45:00\"\n\"Harju maakond\"\n\n\n\"2014-10-24 13:45:00\"\n\"Harju maakond\"\n\n\n\"2014-08-11 00:00:00\"\n\"Harju maakond\"\n\n\n\"2014-11-17 17:32:00\"\n\"Harju maakond\"\n\n\n\"2015-04-28 07:55:00\"\n\"Harju maakond\""
  },
  {
    "objectID": "dataframes-presentation.html#expressions",
    "href": "dataframes-presentation.html#expressions",
    "title": "Python dataframes with pandas and polars",
    "section": "Expressions",
    "text": "Expressions\nExpressions are abstract, composable data transformations that are executed with a context that provides data.\n\naccidents.select(pl.col(\"date\")).head()\n\n\nshape: (5, 1)\n\n\n\ndate\n\n\nstr\n\n\n\n\n\"2014-10-24 08:45:00\"\n\n\n\"2014-10-24 13:45:00\"\n\n\n\"2014-08-11 00:00:00\"\n\n\n\"2014-11-17 17:32:00\"\n\n\n\"2015-04-28 07:55:00\""
  },
  {
    "objectID": "dataframes-presentation.html#they-can-be-composed",
    "href": "dataframes-presentation.html#they-can-be-composed",
    "title": "Python dataframes with pandas and polars",
    "section": "They can be composed",
    "text": "They can be composed\nWhat the biggest accident, in terms of killed or injured?\n\n\naccidents.select(\n    # select 'killed'\n    pl.col(\"killed\")\n    # add 'injured'\n    .add(pl.col(\"injured\"))\n    # give the result a new column name\n    .alias(\"killed_or_injured\")\n    # identify the max value\n    .max())\n\n\nshape: (1, 1)\n\n\n\nkilled_or_injured\n\n\ni64\n\n\n\n\n23"
  },
  {
    "objectID": "dataframes-presentation.html#and-they-work-in-multiple-contexts",
    "href": "dataframes-presentation.html#and-they-work-in-multiple-contexts",
    "title": "Python dataframes with pandas and polars",
    "section": "And they work in multiple contexts",
    "text": "And they work in multiple contexts\n\nselect()\nfilter()\nwith_columns(): mutating dataframes\ngroup_by() and aggregations"
  },
  {
    "objectID": "dataframes-presentation.html#filtering-rows-1",
    "href": "dataframes-presentation.html#filtering-rows-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Filtering rows",
    "text": "Filtering rows\nHow many accidents were in Harju county?\n\naccidents.filter(pl.col(\"county\").eq(\"Harju maakond\")).shape\n\n(7000, 8)\n\n\n\n\naccidents.filter(pl.col(\"county\").str.contains(\"Harju\")).shape\n\n(7000, 8)"
  },
  {
    "objectID": "dataframes-presentation.html#mutating-dataframes-1",
    "href": "dataframes-presentation.html#mutating-dataframes-1",
    "title": "Python dataframes with pandas and polars",
    "section": "Mutating dataframes",
    "text": "Mutating dataframes\nwith_columns() + expressions\n\n\naccidents = accidents.with_columns(\n    pl.col(\"killed\").add(pl.col(\"injured\")).alias(\"killed_or_injured\"),\n    pl.col(\"killed\").add(pl.col(\"injured\")).truediv(pl.col(\"persons_involved\")).alias(\"harmed_rate\")\n)\naccidents.select([\"date\", \"persons_involved\", \"killed_or_injured\", \"harmed_rate\"]).head(5)\n\n\nshape: (5, 4)\n\n\n\ndate\npersons_involved\nkilled_or_injured\nharmed_rate\n\n\nstr\ni64\ni64\nf64\n\n\n\n\n\"2014-10-24 08:45:00\"\n2\n1\n0.5\n\n\n\"2014-10-24 13:45:00\"\n2\n1\n0.5\n\n\n\"2014-08-11 00:00:00\"\n2\n1\n0.5\n\n\n\"2014-11-17 17:32:00\"\n2\n2\n1.0\n\n\n\"2015-04-28 07:55:00\"\n2\n1\n0.5"
  },
  {
    "objectID": "dataframes-presentation.html#group-and-summarizeaggregate",
    "href": "dataframes-presentation.html#group-and-summarizeaggregate",
    "title": "Python dataframes with pandas and polars",
    "section": "Group and summarize/aggregate",
    "text": "Group and summarize/aggregate\ngroup_by() + agg() or with_columns()\n\n\nby_county = (accidents\n             .group_by(\"county\")\n             .agg(pl.col(\"killed_or_injured\").sum())\n             .sort(\"killed_or_injured\", descending=True)\n)\nby_county.head()\n\n\nshape: (5, 2)\n\n\n\ncounty\nkilled_or_injured\n\n\nstr\ni64\n\n\n\n\n\"Harju maakond\"\n8423\n\n\n\"Tartu maakond\"\n1968\n\n\n\"Ida-Viru maakond\"\n1348\n\n\n\"Pärnu maakond\"\n1293\n\n\n\"Lääne-Viru maakond\"\n883"
  },
  {
    "objectID": "dataframes-presentation.html#optional-joining-dataframes",
    "href": "dataframes-presentation.html#optional-joining-dataframes",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Joining dataframes",
    "text": "(Optional) Joining dataframes\nWhat’s the per capita accident victim rate?\n\n\ncounty_pop = (pl.read_csv(\"data/county-pop.csv\", skip_rows=2)\n              .rename({\"County\": \"county\", \"Age groups total\": \"population\"})\n              .select([\"county\", \"population\"])\n              # this has \"county\" in the county names, not \"maakond\"\n              .with_columns(pl.col(\"county\").str.replace(\"county\", \"maakond\"))\n              )\n\nby_county_w_pop = by_county.join(county_pop, on=\"county\", how=\"left\")\nby_county_w_pop.head(3)\n\n\nshape: (3, 3)\n\n\n\ncounty\nkilled_or_injured\npopulation\n\n\nstr\ni64\ni64\n\n\n\n\n\"Harju maakond\"\n8423\n598059\n\n\n\"Tartu maakond\"\n1968\n152977\n\n\n\"Ida-Viru maakond\"\n1348\n136240"
  },
  {
    "objectID": "dataframes-presentation.html#optional-joining-dataframes-1",
    "href": "dataframes-presentation.html#optional-joining-dataframes-1",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Joining dataframes",
    "text": "(Optional) Joining dataframes\nNow we can use some simple select + expressions do to the math:\n\n\nby_county_w_pop.select(\n    pl.col(\"county\"), \n    pl.col(\"killed_or_injured\"),\n    pl.col(\"killed_or_injured\").truediv(pl.col(\"population\")).mul(1000).alias(\"rate/1000\")\n    ).head(3)\n\n\nshape: (3, 3)\n\n\n\ncounty\nkilled_or_injured\nrate/1000\n\n\nstr\ni64\nf64\n\n\n\n\n\"Harju maakond\"\n8423\n14.083895\n\n\n\"Tartu maakond\"\n1968\n12.864679\n\n\n\"Ida-Viru maakond\"\n1348\n9.894304"
  },
  {
    "objectID": "dataframes-presentation.html#optional-reshaping-pivoting-dataframes",
    "href": "dataframes-presentation.html#optional-reshaping-pivoting-dataframes",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Reshaping / pivoting dataframes",
    "text": "(Optional) Reshaping / pivoting dataframes\nWe’re going to use a different dataset on reflector usage for this.\n\n\nreflectors = (pl.read_csv(\"data/reflectors.csv\", has_header=True, separator=\";\", skip_rows=2)\n              .filter(pl.col(\"Sex\").ne(\"Men and women\"))\n              .drop([\"Type of data\", \"Year\", \"All age groups (16-64)\"])\n)\nreflectors.head()\n\n\nshape: (5, 7)\n\n\n\nReflector use\nSex\n16-24\n25-34\n35-44\n45-54\n55-64\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"Never\"\n\"Men\"\n14.3\n12.4\n7.2\n3.9\n2.7\n\n\n\"Never\"\n\"Women\"\n8.8\n5.0\n4.6\n2.0\n2.5\n\n\n\"Sometimes\"\n\"Men\"\n46.7\n36.2\n30.9\n26.1\n28.7\n\n\n\"Sometimes\"\n\"Women\"\n29.6\n26.0\n20.6\n14.8\n13.7\n\n\n\"Nearly always\"\n\"Men\"\n34.3\n40.5\n52.2\n58.6\n55.9"
  },
  {
    "objectID": "dataframes-presentation.html#optional-reshaping-pivoting-dataframes-1",
    "href": "dataframes-presentation.html#optional-reshaping-pivoting-dataframes-1",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Reshaping / pivoting dataframes",
    "text": "(Optional) Reshaping / pivoting dataframes\n\nreflectors = (reflectors\n              .unpivot(index=[\"Reflector use\", \"Sex\"], \n                       variable_name=\"age_group\", \n                       value_name=\"percentage\")\n)\nreflectors.head()\n\n\nshape: (5, 4)\n\n\n\nReflector use\nSex\nage_group\npercentage\n\n\nstr\nstr\nstr\nf64\n\n\n\n\n\"Never\"\n\"Men\"\n\"16-24\"\n14.3\n\n\n\"Never\"\n\"Women\"\n\"16-24\"\n8.8\n\n\n\"Sometimes\"\n\"Men\"\n\"16-24\"\n46.7\n\n\n\"Sometimes\"\n\"Women\"\n\"16-24\"\n29.6\n\n\n\"Nearly always\"\n\"Men\"\n\"16-24\"\n34.3"
  },
  {
    "objectID": "dataframes-presentation.html#plot-reflector-use-by-age-and-gender",
    "href": "dataframes-presentation.html#plot-reflector-use-by-age-and-gender",
    "title": "Python dataframes with pandas and polars",
    "section": "Plot reflector use by age and gender",
    "text": "Plot reflector use by age and gender\n\n(reflectors\n .filter(pl.col(\"Reflector use\").eq(\"Never\"))\n .plot.line(x = \"age_group\", y = \"percentage\", color = \"Sex\")\n .properties(width=700, height=300)\n)"
  },
  {
    "objectID": "dataframes-presentation.html#modified-plot",
    "href": "dataframes-presentation.html#modified-plot",
    "title": "Python dataframes with pandas and polars",
    "section": "Modified plot",
    "text": "Modified plot\nOne category is “Never walk on dark streets, roads”…🧐\n\n\n(reflectors\n .with_columns(pl.col(\"Reflector use\").str.replace(\"Never walk on dark streets, roads\", \"Never\"))\n .group_by([\"Reflector use\", \"Sex\", \"age_group\"])\n .agg(pl.col(\"percentage\").sum())\n .filter(pl.col(\"Reflector use\").eq(\"Never\"))\n .sort([\"age_group\", \"Sex\"])\n .plot.line(x = \"age_group\", y = \"percentage\", color = \"Sex\")\n .properties(width=700, height=300)\n)"
  },
  {
    "objectID": "dataframes-presentation.html#why-you-should-plot-your-data",
    "href": "dataframes-presentation.html#why-you-should-plot-your-data",
    "title": "Python dataframes with pandas and polars",
    "section": "Why you should plot your data 😼",
    "text": "Why you should plot your data 😼\n\n\n\ndf1 = pl.read_csv(\"data/dataset1.csv\")\ndf1.shape\n\n(142, 2)\n\n\n\n\nstats = [\"mean\", \"std\", \"25%\", \"75%\"]\n(df1\n .describe()\n .filter(pl.col(\"statistic\").is_in(stats))\n)\n\n\nshape: (4, 3)\n\n\n\nstatistic\nx\ny\n\n\nstr\nf64\nf64\n\n\n\n\n\"mean\"\n54.2661\n47.834721\n\n\n\"std\"\n16.769825\n26.939743\n\n\n\"25%\"\n39.706326\n24.46783\n\n\n\"75%\"\n69.359559\n71.806616\n\n\n\n\n\n\n\n\n\ndf2 = pl.read_csv(\"data/dataset2.csv\")\ndf2.shape\n\n(142, 2)\n\n\n\n\nstats = [\"mean\", \"std\", \"25%\", \"75%\"]\n(df2\n .describe()\n .filter(pl.col(\"statistic\").is_in(stats))\n)\n\n\nshape: (4, 3)\n\n\n\nstatistic\nx\ny\n\n\nstr\nf64\nf64\n\n\n\n\n\"mean\"\n54.263273\n47.832253\n\n\n\"std\"\n16.765142\n26.935403\n\n\n\"25%\"\n44.1026\n25.2564\n\n\n\"75%\"\n64.8718\n69.1026"
  },
  {
    "objectID": "dataframes-presentation.html#why-you-should-plot-pt2",
    "href": "dataframes-presentation.html#why-you-should-plot-pt2",
    "title": "Python dataframes with pandas and polars",
    "section": "Why you should plot pt2",
    "text": "Why you should plot pt2\n\n\n\ndf1.plot.point(\"x\", \"y\")\n\n\n\n\n\n\n\n\n\ndf2.plot.point(\"x\", \"y\")\n\n\n\n\n\n\n\n\n\n🦖🦖🦖🦖🦖🦖🦖🦖🦖🦖🦖🦖🦖"
  },
  {
    "objectID": "dataframes-presentation.html#andy-is-a-polars-stan",
    "href": "dataframes-presentation.html#andy-is-a-polars-stan",
    "title": "Python dataframes with pandas and polars",
    "section": "Andy is a polars stan",
    "text": "Andy is a polars stan\n\n\n\n\n\n\n\n\n\nhttps://star-history.com/#apache/spark&pola-rs/polars&pandas-dev/pandas&narwhals-dev/narwhals&duckdb/duckdb&Date"
  },
  {
    "objectID": "dataframes-presentation.html#comparison",
    "href": "dataframes-presentation.html#comparison",
    "title": "Python dataframes with pandas and polars",
    "section": "Comparison",
    "text": "Comparison\n\n\npandas\n\n✅ Very widely used and supported\n✅ Stable\n❓ More imperative, traditional API\n❌ Inconsistent API, multiple ways of doing the same thing\n\n\npolars\n\n✅ More consistent, functional-style API\n✅ Faster, less memory footprint\n✅ Works with OOM datasets out of the box\n❌ API still changing"
  },
  {
    "objectID": "dataframes-presentation.html#other-frameworks",
    "href": "dataframes-presentation.html#other-frameworks",
    "title": "Python dataframes with pandas and polars",
    "section": "Other frameworks",
    "text": "Other frameworks\n\n\nNarwhals\nDuckDB"
  },
  {
    "objectID": "dataframes-presentation.html#thank-you",
    "href": "dataframes-presentation.html#thank-you",
    "title": "Python dataframes with pandas and polars",
    "section": "Thank you!",
    "text": "Thank you!\nScan this and let us know how we did 🤗"
  },
  {
    "objectID": "dataframes-presentation.html#open-dataframes.ipynb",
    "href": "dataframes-presentation.html#open-dataframes.ipynb",
    "title": "Python dataframes with pandas and polars",
    "section": "Open dataframes.ipynb",
    "text": "Open dataframes.ipynb"
  },
  {
    "objectID": "dataframes-presentation.html#to-just-follow-along",
    "href": "dataframes-presentation.html#to-just-follow-along",
    "title": "Python dataframes with pandas and polars",
    "section": "To just follow along",
    "text": "To just follow along"
  },
  {
    "objectID": "dataframes-presentation.html#setting-up---link-to-repo",
    "href": "dataframes-presentation.html#setting-up---link-to-repo",
    "title": "Python dataframes with pandas and polars",
    "section": "Setting up - link to repo",
    "text": "Setting up - link to repo"
  },
  {
    "objectID": "dataframes-presentation.html#while-we-wait",
    "href": "dataframes-presentation.html#while-we-wait",
    "title": "Python dataframes with pandas and polars",
    "section": "While we wait",
    "text": "While we wait\n\n\nWho has used pandas before?\npolars?\nAnother data framework in Python, e.g. database + SQL?\nDoes code like this mean anything to you?\ntitanic %&gt;% \n  select(Pclass, Survived) %&gt;% \n  group_by(Pclass) %&gt;% \n  summarize(passengers = n(), surv_rate = mean(Survived))"
  },
  {
    "objectID": "dataframes-presentation.html#optional-cleaning-the-accidents-data",
    "href": "dataframes-presentation.html#optional-cleaning-the-accidents-data",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) Cleaning the accidents data",
    "text": "(Optional) Cleaning the accidents data\nSee notebook."
  },
  {
    "objectID": "dataframes-presentation.html#optional-more-on-indices",
    "href": "dataframes-presentation.html#optional-more-on-indices",
    "title": "Python dataframes with pandas and polars",
    "section": "(Optional) More on indices",
    "text": "(Optional) More on indices\nSee notebook."
  },
  {
    "objectID": "dataframes-presentation.html#polars-is-different-from-pandas",
    "href": "dataframes-presentation.html#polars-is-different-from-pandas",
    "title": "Python dataframes with pandas and polars",
    "section": "polars is different from pandas",
    "text": "polars is different from pandas\n\n\nUse methods, not []; no index\nCompose methods (methods chaining)\nExpressions\n\n\n\nimport pyarrow\n\ndf = pl.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n# to make this a pandas dataframe\n# (requires pyarrow)\ndf_pd = df.to_pandas()\n# to convert it back to polars dataframe\ndf_pl = pl.DataFrame(df_pd)"
  }
]